<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article">
  <head><script src="/langchain_project_book/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=langchain_project_book/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.134.2">
    <meta name="generator" content="Relearn 7.0.1+72a875f1db967152c77914cff4d53f8fcee0e619">
    <meta name="description" content="In this book, we emphasize the use of open-source LLMs over closed-source alternatives for their benefits such as freedom, flexibility, vendor unlock, and code reusability. Personally, I advocate for and actively contribute to the open-source community. Various platforms like Hugging Face, Cohere, GPT4All, etc., offer broad repositories of open-source LLMs.
Choosing LangChain with open-source models from Hugging Face via Hugging Face APIs provides flexibility. Alternatively, one can directly orchestrate LLMs and their chains without relying on Hugging Face. Both approaches will be covered in the upcoming chapters.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Configure Models :: LangChain AI">
    <meta name="twitter:description" content="In this book, we emphasize the use of open-source LLMs over closed-source alternatives for their benefits such as freedom, flexibility, vendor unlock, and code reusability. Personally, I advocate for and actively contribute to the open-source community. Various platforms like Hugging Face, Cohere, GPT4All, etc., offer broad repositories of open-source LLMs.
Choosing LangChain with open-source models from Hugging Face via Hugging Face APIs provides flexibility. Alternatively, one can directly orchestrate LLMs and their chains without relying on Hugging Face. Both approaches will be covered in the upcoming chapters.">
    <meta property="og:url" content="http://localhost:1313/langchain_project_book/tools_n_lib/config_model/index.html">
    <meta property="og:site_name" content="LangChain AI">
    <meta property="og:title" content="Configure Models :: LangChain AI">
    <meta property="og:description" content="In this book, we emphasize the use of open-source LLMs over closed-source alternatives for their benefits such as freedom, flexibility, vendor unlock, and code reusability. Personally, I advocate for and actively contribute to the open-source community. Various platforms like Hugging Face, Cohere, GPT4All, etc., offer broad repositories of open-source LLMs.
Choosing LangChain with open-source models from Hugging Face via Hugging Face APIs provides flexibility. Alternatively, one can directly orchestrate LLMs and their chains without relying on Hugging Face. Both approaches will be covered in the upcoming chapters.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Tools and Libraries">
    <meta property="article:published_time" content="2024-10-28T20:42:25+08:00">
    <meta property="article:modified_time" content="2024-10-28T20:42:25+08:00">
    <meta itemprop="name" content="Configure Models :: LangChain AI">
    <meta itemprop="description" content="In this book, we emphasize the use of open-source LLMs over closed-source alternatives for their benefits such as freedom, flexibility, vendor unlock, and code reusability. Personally, I advocate for and actively contribute to the open-source community. Various platforms like Hugging Face, Cohere, GPT4All, etc., offer broad repositories of open-source LLMs.
Choosing LangChain with open-source models from Hugging Face via Hugging Face APIs provides flexibility. Alternatively, one can directly orchestrate LLMs and their chains without relying on Hugging Face. Both approaches will be covered in the upcoming chapters.">
    <meta itemprop="datePublished" content="2024-10-28T20:42:25+08:00">
    <meta itemprop="dateModified" content="2024-10-28T20:42:25+08:00">
    <meta itemprop="wordCount" content="451">
    <title>Configure Models :: LangChain AI</title>
    <link href="/langchain_project_book/css/fontawesome-all.min.css?1730158732" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/fontawesome-all.min.css?1730158732" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/nucleus.css?1730158732" rel="stylesheet">
    <link href="/langchain_project_book/css/auto-complete.css?1730158732" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/auto-complete.css?1730158732" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/perfect-scrollbar.min.css?1730158732" rel="stylesheet">
    <link href="/langchain_project_book/css/fonts.css?1730158732" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/fonts.css?1730158732" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/theme.css?1730158732" rel="stylesheet">
    <link href="/langchain_project_book/css/theme-auto.css?1730158732" rel="stylesheet" id="R-variant-style">
    <link href="/langchain_project_book/css/chroma-auto.css?1730158732" rel="stylesheet" id="R-variant-chroma-style">
    <link href="/langchain_project_book/css/print.css?1730158732" rel="stylesheet" media="print">
    <script src="/langchain_project_book/js/variant.js?1730158732"></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/langchain_project_book';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      // variant stuff
      window.variants && variants.init( [ 'auto' ] );
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script>
  </head>
  <body class="mobile-support html" data-url="/langchain_project_book/tools_n_lib/config_model/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper"> 
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/langchain_project_book/index.html"><span itemprop="name">LangChain Project Handbook</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/langchain_project_book/tools_n_lib/index.html"><span itemprop="name">Tools and Libraries</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><span itemprop="name">Configure Models</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/tools_n_lib/install_ide/index.html" title="Install an IDE (ðŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/tools_n_lib/summary/index.html" title="Summary (ðŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable tools_n_lib" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="configure-models">Configure Models</h1>

<p>In this book, we emphasize the use of open-source LLMs over closed-source alternatives for their benefits such as freedom, flexibility, vendor unlock, and code reusability. Personally, I advocate for and actively contribute to the open-source community. Various platforms like Hugging Face, Cohere, GPT4All, etc., offer broad repositories of open-source LLMs.</p>
<p>Choosing LangChain with open-source models from Hugging Face via Hugging Face APIs provides flexibility. Alternatively, one can directly orchestrate LLMs and their chains without relying on Hugging Face. Both approaches will be covered in the upcoming chapters.</p>
<h4 id="use-repo_id-online-of-hugging-face">Use <code>repo_id</code> online of Hugging Face</h4>
<p>You have the option to establish a direct connection to the model through Hugging Face. This allows you to leverage the computational power of loading LLMs from a remote platform when local computing resources are limited. It also serves as a convenient starting point for beginners with a straightforward solution.</p>
<div class="highlight wrap-code"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#75715e"># os.environ[&#39;HUGGINGFACEHUB_API_TOKEN&#39;] = &#39;HF_API_KEY&#39;</span>
</span></span><span style="display:flex;"><span>HUGGINGFACEHUB_API_TOKEN <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;HUGGINGFACEHUB_API_TOKEN&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.prompts <span style="color:#f92672">import</span> PromptTemplate
</span></span><span style="display:flex;"><span>template <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;Question: </span><span style="color:#e6db74">{question}</span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Answer: &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prompt <span style="color:#f92672">=</span> PromptTemplate(template<span style="color:#f92672">=</span>template,
</span></span><span style="display:flex;"><span>input_variables<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;question&#39;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># user question</span>
</span></span><span style="display:flex;"><span>question <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Which NFL team won the Super Bowl in the 2010 season?&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.llms <span style="color:#f92672">import</span> HuggingFaceEndpoint
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.chains <span style="color:#f92672">import</span> LLMChain
</span></span><span style="display:flex;"><span><span style="color:#75715e"># initialize Hub LLM</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># repo_id = &#34;google/flan-t5-xxl&#34; # flan-t5&#39;s available too</span>
</span></span><span style="display:flex;"><span>repo_id <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;mistralai/Mistral-7B-Instruct-v0.2&#34;</span>
</span></span><span style="display:flex;"><span>hub_llm <span style="color:#f92672">=</span> HuggingFaceEndpoint(
</span></span><span style="display:flex;"><span>    repo_id<span style="color:#f92672">=</span>repo_id,
</span></span><span style="display:flex;"><span>    temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create prompt template &gt; LLM chain</span>
</span></span><span style="display:flex;"><span>llm_chain <span style="color:#f92672">=</span> LLMChain(prompt<span style="color:#f92672">=</span>prompt, llm<span style="color:#f92672">=</span>hub_llm)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># ask the user question about NFL 2010</span>
</span></span><span style="display:flex;"><span>print(llm_chain<span style="color:#f92672">.</span>invoke(question))</span></span></code></pre></div>
<p>In above example, we call <code>HuggingFaceEndpoint</code> class to access the <code>Mistral-7B-Instruct</code> model from Hugging Face platform directly without having to download any model when you donâ€™t have enough capacity locally. The code also shows how to access <code>google/flan-t5-xxl</code> model.</p>
<h4 id="use-model-offline-of-hugging-face">Use <code>model</code> offline of Hugging Face</h4>
<p>If data security is a priority and you aim to confine all queries and computations within a private network, aligning with enterprise security standards, or if you possess enough local computing power, like an Nvidia RTX 4090 graphic card on my Manjaro Linux, you have the option to download models, including Mistral and Falcon, directly to your local storage. Follow the following configuration steps to enable local execution of all processes.</p>
<p>The provided sample code demonstrates how to download an embedding model from Hugging Face for local utilization. Then embed a single line of text and print out the results with <code>embed_query</code> method.</p>
<div class="highlight wrap-code"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.embeddings <span style="color:#f92672">import</span> HuggingFaceEmbeddings
</span></span><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> HuggingFaceEmbeddings(
</span></span><span style="display:flex;"><span>    model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;This is a test document.&#34;</span>
</span></span><span style="display:flex;"><span>query_result <span style="color:#f92672">=</span> embedding<span style="color:#f92672">.</span>embed_query(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(query_result[:<span style="color:#ae81ff">3</span>])
</span></span><span style="display:flex;"><span>print(type(query_result))</span></span></code></pre></div>
<p>In the above case, we&rsquo;re using <code>sentence-transformers/paraphrase-multilingual-MiniLM</code> which is downloaded locally from Hugging Face repository.</p>
<p>By default, the download resides in <code>~/.cache/torch/sentence_transformers</code>.</p>
<p>For example:</p>
<div class="highlight wrap-code"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cd ~/.cache/torch/sentence_transformers; ls
</span></span><span style="display:flex;"><span>sentence-transformers_all-MiniLM-L6-v2
</span></span><span style="display:flex;"><span>sentence-transformers_all-mpnet-base-v2
</span></span><span style="display:flex;"><span>sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>du -ksh
</span></span><span style="display:flex;"><span>983M .</span></span></code></pre></div>
<p>I have 3 small embedding models, from sentence-transformers, downloaded locally, and they&rsquo;re total less than 1G size.</p>

  <footer class="footline">
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/langchain_project_book/index.html">
LangChain AI
          </a>
        </div>
        <script>
          window.index_js_url="/langchain_project_book/searchindex.js?1730158732";
        </script>
        <search><form action="/langchain_project_book/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
        <script>
          var contentLangs=['en'];
        </script>
        <script src="/langchain_project_book/js/auto-complete.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.min.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.stemmer.support.min.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.multi.min.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.en.min.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/search.js?1730158732" defer></script>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <ul>
          <li><a class="padding" href="/langchain_project_book/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
        </ul>
        <hr class="padding">
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div id="R-topics">
          <ul class="enlarge morespace collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/preface/index.html"><a class="padding" href="/langchain_project_book/preface/index.html">Preface</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/index.html"><a class="padding" href="/langchain_project_book/fundamentals/index.html">LangChain Fundamentals</a><ul id="R-subsections-c6757c34957c6808b13ecd5148aeca96" class="collapsible-menu"></ul></li>
            <li class="parent " data-nav-id="/langchain_project_book/tools_n_lib/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/index.html">Tools and Libraries</a><ul id="R-subsections-cc34bf23dab60f9112ee939495610dcf" class="collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/install_lc/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/install_lc/index.html">Install LangChain</a></li>
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/setup_env/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/setup_env/index.html">Set up your Environment</a></li>
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/install_ide/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/install_ide/index.html">Install an IDE</a></li>
            <li class="active " data-nav-id="/langchain_project_book/tools_n_lib/config_model/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/config_model/index.html">Configure Models</a></li>
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/summary/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/summary/index.html">Summary</a></li></ul></li>
            <li class="" data-nav-id="/langchain_project_book/doc_sum/index.html"><a class="padding" href="/langchain_project_book/doc_sum/index.html">Document Summarization</a><ul id="R-subsections-76bbd5376befb633d2052d0ea4508ef3" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/index.html">Ticketing System</a><ul id="R-subsections-eaa6b154ff31d8e1af72e9555a67f96a" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/index.html">KnowledgeBase Semantic Analysis</a><ul id="R-subsections-c718aa372d1e4f26c29659df75d5d07f" class="collapsible-menu"></ul></li>
          </ul>
        </div>
        <div class="padding footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div>
        <div id="R-menu-footer">
          <hr class="padding default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter">
          <div id="R-prefooter" class="footerLangSwitch footerVariantSwitch footerVisitedLinks">
            <ul>
              <li id="R-select-language-container" class="footerLangSwitch">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-language"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <label class="a11y-only" for="R-select-language">Language</label>
                    <select id="R-select-language" onchange="location = this.querySelector( this.value ).dataset.url;">
                      <option id="R-select-language-en" value="#R-select-language-en" data-url="/langchain_project_book/tools_n_lib/config_model/index.html" lang="en-us" selected></option>
                    </select>
                  </div>
                  <div class="clear"></div>
                </div>
              </li>
              <li id="R-select-variant-container" class="footerVariantSwitch">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-paint-brush"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <label class="a11y-only" for="R-select-variant">Theme</label>
                    <select id="R-select-variant" onchange="window.variants && variants.changeVariant( this.value );">
                      <option id="R-select-variant-auto" value="auto" selected>Auto</option>
                    </select>
                  </div>
                  <div class="clear"></div>
                </div>
                <script>window.variants && variants.markSelectedVariant();</script>
              </li>
              <li class="footerVisitedLinks">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-history"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <button onclick="clearHistory();">Clear History</button>
                  </div>
                  <div class="clear"></div>
                </div>
              </li>
            </ul>
          </div>
          <div id="R-footer" class="footerFooter showFooter">
        <p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p>
          </div>
        </div>
      </div>
    </aside>
    <script src="/langchain_project_book/js/clipboard.min.js?1730158732" defer></script>
    <script src="/langchain_project_book/js/perfect-scrollbar.min.js?1730158732" defer></script>
    <script src="/langchain_project_book/js/theme.js?1730158732" defer></script>
  </body>
</html>
