<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/langchain_project_book/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=langchain_project_book/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.131.0">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="It’s a little surprising to me that Facebook AI Similarity Search (FAISS) was released in 2017. An explanation from its official documentation:
… FAISS, a library that allows us to quickly search for multimedia documents that are similar to each other - a challenge where traditional query search engines fall short. We’ve built nearest-neighbor search implementations for billion-scale data sets that are some 8.5x faster than the previous reported state-of-the-art, along with the fastest k-selection algorithm on the GPU known in the literature.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Defining Embedding Model and VectorStore with FAISS :: LangChain AI">
    <meta name="twitter:description" content="It’s a little surprising to me that Facebook AI Similarity Search (FAISS) was released in 2017. An explanation from its official documentation:
… FAISS, a library that allows us to quickly search for multimedia documents that are similar to each other - a challenge where traditional query search engines fall short. We’ve built nearest-neighbor search implementations for billion-scale data sets that are some 8.5x faster than the previous reported state-of-the-art, along with the fastest k-selection algorithm on the GPU known in the literature.">
    <meta property="og:url" content="http://localhost:1313/langchain_project_book/ticketing_sys/define_embed_model_n_vector_with_faiss/index.html">
    <meta property="og:site_name" content="LangChain AI">
    <meta property="og:title" content="Defining Embedding Model and VectorStore with FAISS :: LangChain AI">
    <meta property="og:description" content="It’s a little surprising to me that Facebook AI Similarity Search (FAISS) was released in 2017. An explanation from its official documentation:
… FAISS, a library that allows us to quickly search for multimedia documents that are similar to each other - a challenge where traditional query search engines fall short. We’ve built nearest-neighbor search implementations for billion-scale data sets that are some 8.5x faster than the previous reported state-of-the-art, along with the fastest k-selection algorithm on the GPU known in the literature.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Ticketing System">
    <meta property="article:published_time" content="2024-10-28T21:27:58+08:00">
    <meta property="article:modified_time" content="2024-10-28T21:27:58+08:00">
    <meta itemprop="name" content="Defining Embedding Model and VectorStore with FAISS :: LangChain AI">
    <meta itemprop="description" content="It’s a little surprising to me that Facebook AI Similarity Search (FAISS) was released in 2017. An explanation from its official documentation:
… FAISS, a library that allows us to quickly search for multimedia documents that are similar to each other - a challenge where traditional query search engines fall short. We’ve built nearest-neighbor search implementations for billion-scale data sets that are some 8.5x faster than the previous reported state-of-the-art, along with the fastest k-selection algorithm on the GPU known in the literature.">
    <meta itemprop="datePublished" content="2024-10-28T21:27:58+08:00">
    <meta itemprop="dateModified" content="2024-10-28T21:27:58+08:00">
    <meta itemprop="wordCount" content="708">
    <title>Defining Embedding Model and VectorStore with FAISS :: LangChain AI</title>
    <link href="/langchain_project_book/css/auto-complete/auto-complete.min.css?1755628295" rel="stylesheet">
    <script src="/langchain_project_book/js/auto-complete/auto-complete.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/search-lunr.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/search.js?1755628295" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/langchain_project_book/searchindex.en.js?1755628295";
    </script>
    <script src="/langchain_project_book/js/lunr/lunr.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.stemmer.support.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.multi.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.en.min.js?1755628295" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/langchain_project_book/fonts/fontawesome/css/fontawesome-all.min.css?1755628295" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/fonts/fontawesome/css/fontawesome-all.min.css?1755628295" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/perfect-scrollbar/perfect-scrollbar.min.css?1755628295" rel="stylesheet">
    <link href="/langchain_project_book/css/theme.css?1755628295" rel="stylesheet">
    <link href="/langchain_project_book/css/format-html.css?1755628295" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/ticketing_sys\/define_embed_model_n_vector_with_faiss\/index.html';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/langchain_project_book';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
  </head>
  <body class="mobile-support html" data-url="/langchain_project_book/ticketing_sys/define_embed_model_n_vector_with_faiss/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper"> 
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/langchain_project_book/index.html"><span itemprop="name">LangChain Project Handbook</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/langchain_project_book/ticketing_sys/index.html"><span itemprop="name">Ticketing System</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Defining Embedding Model and VectorStore with FAISS</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/ticketing_sys/data_processing/index.html" title="Data Processing (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/ticketing_sys/complete_code/index.html" title="Complete Code (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable ticketing_sys" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="defining-embedding-model-and-vectorstore-with-faiss">Defining Embedding Model and VectorStore with FAISS</h1>

<p>It&rsquo;s a little surprising to me that Facebook AI Similarity Search (FAISS) was released in 2017. An explanation from its official documentation:</p>
<blockquote>
<p>&hellip; FAISS, a library that allows us to quickly search for multimedia documents that are similar to each other - a challenge where traditional query search engines fall short. We’ve built nearest-neighbor search implementations for billion-scale data sets that are some 8.5x faster than the previous reported state-of-the-art, along with the fastest k-selection algorithm on the GPU known in the literature. This lets us break some records, including the first k-nearest-neighbor graph constructed on 1 billion high-dimensional vectors.</p>
</blockquote>
<p>Traditional databases consist of structured tables filled with symbolic data. For instance, an image collection would be organized into a table with each photo represented by a row, containing details like an image ID and descriptive text. These rows can also connect to entries from other tables, such as linking an image with people to a table of names.</p>
<p>AI tools, including text embedding methods like word2vec or convolutional neural network (CNN) descriptors trained with deep learning, generate high-dimensional vectors. These vectors offer a more potent and adaptable representation compared to fixed symbolic representations. However, traditional databases designed for SQL queries are not equipped to handle these new vector representations. The sheer volume of new multimedia content generates billions of vectors, and more critically, identifying similar entries involves finding similar high-dimensional vectors, a task that is inefficient and often impossible with conventional query languages.</p>
<p>Let&rsquo;s install FAISS and its dependencies.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>pip install <span style="color:#f92672">-</span>U langchain<span style="color:#f92672">-</span>community faiss<span style="color:#f92672">-</span>cpu langchain<span style="color:#f92672">-</span>openai tiktoken</span></span></code></pre></div>
<p>Then define an embedding model using <code>paraphrase-multilingual_MiniLM</code></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_huggingface.embeddings <span style="color:#f92672">import</span> HuggingFaceEmbeddings
</span></span><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> HuggingFaceEmbeddings(
</span></span><span style="display:flex;"><span>    model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#34;</span>)</span></span></code></pre></div>
<p>Use <code>FAISS.from_documents</code> to insert the embedded document into FAISS vectorstore. Then define <code>retriever</code></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.vectorstores <span style="color:#f92672">import</span> FAISS
</span></span><span style="display:flex;"><span>vectorstore <span style="color:#f92672">=</span> FAISS<span style="color:#f92672">.</span>from_documents(data, embedding)
</span></span><span style="display:flex;"><span>retriever <span style="color:#f92672">=</span> vectorstore<span style="color:#f92672">.</span>as_retriever()</span></span></code></pre></div>
<p>The last line of code snippet converts the <code>vectorstore</code> into a <code>retriever</code> class. This allows us to easily use it in other LangChain methods, which largely work with retrievers.</p>
<h4 id="compressed-retriever">Compressed Retriever</h4>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>In our project, we found that:</p>
<p>The LLM generates a predicted result if the RAG (Retrieval-Augmented Generation) cannot find an existing answer from <code>similarity_search</code>. Or the retrieved documents contain too much irrelevant information and are distracting the LLM. This is unacceptable when proposing such a solution to our customers. Technically, if the vector database does not have a relative output, it should indicate that it does not know, without causing confusion with predictions made by the LLM.</p>
<p>Often, the most relevant information for a query may be buried within documents containing a significant amount of irrelevant text. Passing the full document (or spreadsheet, and CSV) through your application can lead to more expensive LLM calls and poorer responses.</p>
<p>Contextual compression is a solution to this problem. The idea is simple: instead of immediately returning the retrieved documents as-is, you can compress them using the context of the given query, ensuring that only the relevant information is returned. &ldquo;Compressing&rdquo; here refers to both reducing the contents of individual documents and filtering out documents entirely.</p>
<p>To use the Contextual Compression Retriever, you&rsquo;ll need:</p>
<ul>
<li>A Base Retriever</li>
<li>A Context Compressor</li>
</ul>
<p>The Contextual Compression Retriever passes queries to the base retriever, takes the initial documents, and then passes them through the Context Compressor. The Context Compressor then shortens the list of documents by reducing their contents or dropping them altogether.</p>
<blockquote>
<p>Reference &gt; <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/" rel="external" target="_blank">https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/</a></p>
</blockquote>
<p>Here&rsquo;s an example:</p>
<head>
    <script src="https://cdn.jsdelivr.net/gh/jmnote/plantuml-encoder@1.2.4/dist/plantuml-encoder.min.js" integrity="sha256-Qsk2KRBCN5qVZX7B+8+2IvQl1Aqc723qV1tBCQaVoqo=" crossorigin="anonymous"></script>
</head>
<body>
    <pre class="language-plantuml">
    
rectangle ContextualCompressionRetriever {
    file base_retriever
    file base_compressor
}

file compression_retriever
note bottom of compression_retriever: new retriever, used in chain

base_retriever -> base_compressor
ContextualCompressionRetriever -> compression_retriever

    </pre>
    <script>
    (function(){
      let plantumlPrefix = "language-plantuml";
      Array.prototype.forEach.call(document.querySelectorAll("[class^=" + plantumlPrefix + "]"), function(code){
        
        if (!code.previousElementSibling || !code.previousElementSibling.classList.contains('plantuml-image')) {
          let image = document.createElement("IMG");
          image.loading = 'lazy'; 
          image.className = 'plantuml-image'; 
          image.src = 'http://www.plantuml.com/plantuml/svg/~1' + plantumlEncoder.encode(code.innerText);
          code.parentNode.insertBefore(image, code);
          code.style.display = 'none';
        }
      });
    })();
    </script>
</body>
</html>


<p>Figure 5.3 Contextual Compression Retriever logic</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.retrievers.contextual_compression <span style="color:#f92672">import</span> ContextualCompressionRetriever
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.retrievers.document_compressors <span style="color:#f92672">import</span> LLMChainExtractor
</span></span><span style="display:flex;"><span>compressor <span style="color:#f92672">=</span> LLMChainExtractor<span style="color:#f92672">.</span>from_llm(llm)
</span></span><span style="display:flex;"><span>compression_retriever <span style="color:#f92672">=</span> ContextualCompressionRetriever(
</span></span><span style="display:flex;"><span>    base_compressor<span style="color:#f92672">=</span>compressor, base_retriever<span style="color:#f92672">=</span>retriever
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## you can query with similar_search</span>
</span></span><span style="display:flex;"><span>compressed_docs <span style="color:#f92672">=</span> compression_retriever<span style="color:#f92672">.</span>invoke(query)
</span></span><span style="display:flex;"><span>pprint(compressed_docs)</span></span></code></pre></div>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<h4 id="fix-hallucination-with-retrievalqawithsourceschain">Fix Hallucination with <code>RetrievalQAWithSourcesChain</code></h4>
<p>While we cannot entirely safeguard ourselves from convincing yet false hallucinations generated by the language model, it&rsquo;s important to acknowledge that such occurrences are possible and that it&rsquo;s unlikely we can completely eliminate this issue. However, we can enhance our confidence in the responses provided by incorporating citations into the answers. This can be achieved by utilizing a variant of the <code>RetrievalQA</code> chain, known as <code>RetrievalQAWithSourcesChain</code>, which allows users to trace the origin of the information.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.chains.qa_with_sources.retrieval <span style="color:#f92672">import</span> RetrievalQAWithSourcesChain
</span></span><span style="display:flex;"><span>chain <span style="color:#f92672">=</span> RetrievalQAWithSourcesChain<span style="color:#f92672">.</span>from_chain_type(
</span></span><span style="display:flex;"><span>    llm<span style="color:#f92672">=</span>llm, retriever<span style="color:#f92672">=</span>compression_retriever
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pprint(chain<span style="color:#f92672">.</span>invoke(query))</span></span></code></pre></div>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Oct 28, 2024
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/langchain_project_book/index.html">
            <div class="logo-title">LangChain AI</div>
          </a>
        </div>
        <search><form action="/langchain_project_book/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/index.html"><a class="padding" href="/langchain_project_book/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/preface/index.html"><a class="padding" href="/langchain_project_book/preface/index.html">Preface</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/index.html"><a class="padding" href="/langchain_project_book/fundamentals/index.html">LangChain Fundamentals</a><ul id="R-subsections-0784c4bcc83cbdf0ace68502ac3215e0" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/index.html">Tools and Libraries</a><ul id="R-subsections-fec951202c7c0f845b2452661e4af48e" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/doc_sum/index.html"><a class="padding" href="/langchain_project_book/doc_sum/index.html">Document Summarization</a><ul id="R-subsections-c75a3cc5095251ebcf3be162192ea6c9" class="collapsible-menu"></ul></li>
            <li class="parent " data-nav-id="/langchain_project_book/ticketing_sys/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/index.html">Ticketing System</a><ul id="R-subsections-3f5863c85ccf3c65e662463e67f08191" class="collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/tech_proc/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/tech_proc/index.html">Technical Process</a></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/architecture/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/architecture/index.html">Architecture</a></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/llm_with_gpt4all/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/llm_with_gpt4all/index.html">LLM with GPT4All</a></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/data_processing/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/data_processing/index.html">Data Processing</a></li>
            <li class="active " data-nav-id="/langchain_project_book/ticketing_sys/define_embed_model_n_vector_with_faiss/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/define_embed_model_n_vector_with_faiss/index.html">Defining Embedding Model and VectorStore with FAISS</a></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/complete_code/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/complete_code/index.html">Complete Code</a></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/summary/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/summary/index.html">Summary</a></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/appendix/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/appendix/index.html">Appendix</a></li></ul></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/index.html">KnowledgeBase Semantic Analysis</a><ul id="R-subsections-c498a6349176744d42feaf82a24933fb" class="collapsible-menu"></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/langchain_project_book/js/clipboard/clipboard.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/perfect-scrollbar/perfect-scrollbar.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/theme.js?1755628295" defer></script>
  </body>
</html>
