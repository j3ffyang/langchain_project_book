<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/langchain_project_book/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=langchain_project_book/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.131.0">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="Iâ€™ve divided the code into two sections because the data source is loaded into the vector store only once. After this initial load, queries can be executed against the existing vector store.
Load the data into the vector store Query against the vector store Loading the Data and Creating VectorStore import bs4 from langchain_community.document_loaders import WebBaseLoader loader = WebBaseLoader( web_paths=(&#34;https://andersen.sdu.dk/vaerk/hersholt/TheEmperorsNewClothes_e.html&#34;,), bs_kwargs=dict( parse_only=bs4.SoupStrainer( class_=(&#34;post-content&#34;, &#34;post-title&#34;, &#34;post-header&#34;) ) ), ) documents = loader.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Complete Code :: LangChain AI">
    <meta name="twitter:description" content="Iâ€™ve divided the code into two sections because the data source is loaded into the vector store only once. After this initial load, queries can be executed against the existing vector store.
Load the data into the vector store Query against the vector store Loading the Data and Creating VectorStore import bs4 from langchain_community.document_loaders import WebBaseLoader loader = WebBaseLoader( web_paths=(&#34;https://andersen.sdu.dk/vaerk/hersholt/TheEmperorsNewClothes_e.html&#34;,), bs_kwargs=dict( parse_only=bs4.SoupStrainer( class_=(&#34;post-content&#34;, &#34;post-title&#34;, &#34;post-header&#34;) ) ), ) documents = loader.">
    <meta property="og:url" content="http://localhost:1313/langchain_project_book/knowledgebase_semantic_analysis/complete_code/index.html">
    <meta property="og:site_name" content="LangChain AI">
    <meta property="og:title" content="Complete Code :: LangChain AI">
    <meta property="og:description" content="Iâ€™ve divided the code into two sections because the data source is loaded into the vector store only once. After this initial load, queries can be executed against the existing vector store.
Load the data into the vector store Query against the vector store Loading the Data and Creating VectorStore import bs4 from langchain_community.document_loaders import WebBaseLoader loader = WebBaseLoader( web_paths=(&#34;https://andersen.sdu.dk/vaerk/hersholt/TheEmperorsNewClothes_e.html&#34;,), bs_kwargs=dict( parse_only=bs4.SoupStrainer( class_=(&#34;post-content&#34;, &#34;post-title&#34;, &#34;post-header&#34;) ) ), ) documents = loader.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="KnowledgeBase Semantic Analysis">
    <meta property="article:published_time" content="2024-10-28T22:36:51+08:00">
    <meta property="article:modified_time" content="2024-10-28T22:36:51+08:00">
    <meta itemprop="name" content="Complete Code :: LangChain AI">
    <meta itemprop="description" content="Iâ€™ve divided the code into two sections because the data source is loaded into the vector store only once. After this initial load, queries can be executed against the existing vector store.
Load the data into the vector store Query against the vector store Loading the Data and Creating VectorStore import bs4 from langchain_community.document_loaders import WebBaseLoader loader = WebBaseLoader( web_paths=(&#34;https://andersen.sdu.dk/vaerk/hersholt/TheEmperorsNewClothes_e.html&#34;,), bs_kwargs=dict( parse_only=bs4.SoupStrainer( class_=(&#34;post-content&#34;, &#34;post-title&#34;, &#34;post-header&#34;) ) ), ) documents = loader.">
    <meta itemprop="datePublished" content="2024-10-28T22:36:51+08:00">
    <meta itemprop="dateModified" content="2024-10-28T22:36:51+08:00">
    <meta itemprop="wordCount" content="721">
    <title>Complete Code :: LangChain AI</title>
    <link href="/langchain_project_book/css/auto-complete/auto-complete.min.css?1755628295" rel="stylesheet">
    <script src="/langchain_project_book/js/auto-complete/auto-complete.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/search-lunr.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/search.js?1755628295" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/langchain_project_book/searchindex.en.js?1755628295";
    </script>
    <script src="/langchain_project_book/js/lunr/lunr.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.stemmer.support.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.multi.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.en.min.js?1755628295" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/langchain_project_book/fonts/fontawesome/css/fontawesome-all.min.css?1755628295" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/fonts/fontawesome/css/fontawesome-all.min.css?1755628295" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/perfect-scrollbar/perfect-scrollbar.min.css?1755628295" rel="stylesheet">
    <link href="/langchain_project_book/css/theme.css?1755628295" rel="stylesheet">
    <link href="/langchain_project_book/css/format-html.css?1755628295" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/knowledgebase_semantic_analysis\/complete_code\/index.html';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/langchain_project_book';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
  </head>
  <body class="mobile-support html" data-url="/langchain_project_book/knowledgebase_semantic_analysis/complete_code/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper"> 
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/langchain_project_book/index.html"><span itemprop="name">LangChain Project Handbook</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/langchain_project_book/knowledgebase_semantic_analysis/index.html"><span itemprop="name">KnowledgeBase Semantic Analysis</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Complete Code</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/knowledgebase_semantic_analysis/enable_multiconv_with_history/index.html" title="Enabling Multi-Round Conversations with Chat History (ðŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/knowledgebase_semantic_analysis/summary/index.html" title="Summary (ðŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable knowledgebase_semantic_analysis" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="complete-code">Complete Code</h1>

<p>I&rsquo;ve divided the code into two sections because the data source is loaded into the vector store only once. After this initial load, queries can be executed against the existing vector store.</p>
<ul>
<li>Load the data into the vector store</li>
<li>Query against the vector store</li>
</ul>
<h4 id="loading-the-data-and-creating-vectorstore">Loading the Data and Creating VectorStore</h4>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">import</span> bs4
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.document_loaders <span style="color:#f92672">import</span> WebBaseLoader
</span></span><span style="display:flex;"><span>loader <span style="color:#f92672">=</span> WebBaseLoader(
</span></span><span style="display:flex;"><span>    web_paths<span style="color:#f92672">=</span>(<span style="color:#e6db74">&#34;https://andersen.sdu.dk/vaerk/hersholt/TheEmperorsNewClothes_e.html&#34;</span>,),
</span></span><span style="display:flex;"><span>    bs_kwargs<span style="color:#f92672">=</span>dict(
</span></span><span style="display:flex;"><span>        parse_only<span style="color:#f92672">=</span>bs4<span style="color:#f92672">.</span>SoupStrainer(
</span></span><span style="display:flex;"><span>            class_<span style="color:#f92672">=</span>(<span style="color:#e6db74">&#34;post-content&#34;</span>, <span style="color:#e6db74">&#34;post-title&#34;</span>, <span style="color:#e6db74">&#34;post-header&#34;</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>    ),
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>documents <span style="color:#f92672">=</span> loader<span style="color:#f92672">.</span>load()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.text_splitter <span style="color:#f92672">import</span> RecursiveCharacterTextSplitter
</span></span><span style="display:flex;"><span>splitter <span style="color:#f92672">=</span> RecursiveCharacterTextSplitter(chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>, chunk_overlap<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>)
</span></span><span style="display:flex;"><span>chunks <span style="color:#f92672">=</span> splitter<span style="color:#f92672">.</span>split_documents(documents)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_huggingface.embeddings <span style="color:#f92672">import</span> HuggingFaceEmbeddings
</span></span><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> HuggingFaceEmbeddings(
</span></span><span style="display:flex;"><span>    model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> getpass
</span></span><span style="display:flex;"><span>SUPABASE_URL <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;SUPABASE_URL&#34;</span>)
</span></span><span style="display:flex;"><span>SUPABASE_SERVICE_KEY <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;SUPABASE_SERVICE_KEY&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.vectorstores <span style="color:#f92672">import</span> SupabaseVectorStore
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> supabase.client <span style="color:#f92672">import</span> Client, create_client
</span></span><span style="display:flex;"><span>supabase_url <span style="color:#f92672">=</span> SUPABASE_URL
</span></span><span style="display:flex;"><span>supabase_key <span style="color:#f92672">=</span> SUPABASE_SERVICE_KEY
</span></span><span style="display:flex;"><span>supabase_client <span style="color:#f92672">=</span> create_client(supabase_url, supabase_key)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create a new collection</span>
</span></span><span style="display:flex;"><span>vectorstore <span style="color:#f92672">=</span> SupabaseVectorStore<span style="color:#f92672">.</span>from_documents(
</span></span><span style="display:flex;"><span>    chunks,
</span></span><span style="display:flex;"><span>    embedding <span style="color:#f92672">=</span> embedding,
</span></span><span style="display:flex;"><span>    client <span style="color:#f92672">=</span> supabase_client,
</span></span><span style="display:flex;"><span>    table_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;documents&#34;</span>,
</span></span><span style="display:flex;"><span>    query_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;match_documents&#34;</span>,
</span></span><span style="display:flex;"><span>    chunk_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>,
</span></span><span style="display:flex;"><span>)</span></span></code></pre></div>
<h4 id="querying">Querying</h4>
<p>For convenience, I&rsquo;ve included the values of <code>supabase_url</code> and <code>supabase_key</code> directly in the code to bypass the need for manual input during queries. However, it&rsquo;s crucial to ensure these keys are not exposed when sharing the code with others or when pushing it to a public GitHub repository.</p>
<p>The definition of <code>vectorstore</code> differs a little from its counterpart in the loading section because, during <strong>querying</strong>, there&rsquo;s no need to insert chunks into the vector store.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.vectorstores <span style="color:#f92672">import</span> SupabaseVectorStore
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> supabase.client <span style="color:#f92672">import</span> Client, create_client
</span></span><span style="display:flex;"><span>supabase_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;http://127.0.0.1:8000&#34;</span>
</span></span><span style="display:flex;"><span>supabase_key <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyAgCiAgICAicm9sZSI6ICJhbm9uIiwKICAgICJpc3MiOiAic3VwYWJhc2UtZGVtbyIsCiAgICAiaWF0IjogMTY0MTc2OTIwMCwKICAgICJleHAiOiAxNzk5NTM1NjAwCn0.dc_X5iR_VP_qT0zsiyj_I_OZ2T9FtRU2BBNWN8Bu4GE&#34;</span>
</span></span><span style="display:flex;"><span>supabase_client <span style="color:#f92672">=</span> create_client(supabase_url, supabase_key)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vectorstore <span style="color:#f92672">=</span> SupabaseVectorStore(
</span></span><span style="display:flex;"><span>    embedding<span style="color:#f92672">=</span>embedding,
</span></span><span style="display:flex;"><span>    client<span style="color:#f92672">=</span>supabase_client,
</span></span><span style="display:flex;"><span>    table_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;documents&#34;</span>,
</span></span><span style="display:flex;"><span>    query_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;match_documents&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>retriever <span style="color:#f92672">=</span> vectorstore<span style="color:#f92672">.</span>as_retriever()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_ollama <span style="color:#f92672">import</span> ChatOllama
</span></span><span style="display:flex;"><span>llm <span style="color:#f92672">=</span> ChatOllama(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gemma:2b&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># model=&#34;mistral&#34;,</span>
</span></span><span style="display:flex;"><span>    temperature<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_core.prompts.chat <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    ChatPromptTemplate,
</span></span><span style="display:flex;"><span>    HumanMessagePromptTemplate,
</span></span><span style="display:flex;"><span>    MessagesPlaceholder,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.chains.history_aware_retriever <span style="color:#f92672">import</span> create_history_aware_retriever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>contextualize_q_system_prompt <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Given a chat history and the latest user question &#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;which might reference context in the chat history, &#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;formulate a standalone question which can be understood &#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;without the chat history. Do NOT answer the question, &#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;just reformulate it if needed and otherwise return it as is.&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>contextualize_q_prompt <span style="color:#f92672">=</span> ChatPromptTemplate(
</span></span><span style="display:flex;"><span>    [
</span></span><span style="display:flex;"><span>        (<span style="color:#e6db74">&#34;system&#34;</span>, contextualize_q_system_prompt),
</span></span><span style="display:flex;"><span>        MessagesPlaceholder(<span style="color:#e6db74">&#34;chat_history&#34;</span>),
</span></span><span style="display:flex;"><span>        (<span style="color:#e6db74">&#34;human&#34;</span>, <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{input}</span><span style="color:#e6db74">&#34;</span>),
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>history_aware_retriever <span style="color:#f92672">=</span> create_history_aware_retriever(
</span></span><span style="display:flex;"><span>    llm, retriever, contextualize_q_prompt
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.chains.retrieval <span style="color:#f92672">import</span> create_retrieval_chain
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.chains.combine_documents <span style="color:#f92672">import</span> create_stuff_documents_chain
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>system_prompt <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;You are an assistant for question-answering tasks. &#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;Use the following pieces of retrieved context to answer &#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;the question. If you don&#39;t know the answer, say that you &#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;don&#39;t know. Use three sentences maximum and keep the &#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;answer concise.&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{context}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>qa_prompt <span style="color:#f92672">=</span> ChatPromptTemplate(
</span></span><span style="display:flex;"><span>    [
</span></span><span style="display:flex;"><span>        (<span style="color:#e6db74">&#34;system&#34;</span>, system_prompt),
</span></span><span style="display:flex;"><span>        MessagesPlaceholder(<span style="color:#e6db74">&#34;chat_history&#34;</span>),
</span></span><span style="display:flex;"><span>        (<span style="color:#e6db74">&#34;human&#34;</span>, <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{input}</span><span style="color:#e6db74">&#34;</span>),
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>question_answer_chain <span style="color:#f92672">=</span> create_stuff_documents_chain(llm, qa_prompt)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rag_chain <span style="color:#f92672">=</span> create_retrieval_chain(history_aware_retriever, question_answer_chain)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.globals <span style="color:#f92672">import</span> set_debug, set_verbose
</span></span><span style="display:flex;"><span>set_debug(<span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>set_verbose(<span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_core.messages <span style="color:#f92672">import</span> AIMessage, HumanMessage
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chat_history <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">process_question</span>(question):
</span></span><span style="display:flex;"><span>    ai_msg <span style="color:#f92672">=</span> rag_chain<span style="color:#f92672">.</span>invoke({<span style="color:#e6db74">&#34;input&#34;</span>: question, <span style="color:#e6db74">&#34;chat_history&#34;</span>: chat_history})
</span></span><span style="display:flex;"><span>    chat_history<span style="color:#f92672">.</span>extend(
</span></span><span style="display:flex;"><span>       [
</span></span><span style="display:flex;"><span>           HumanMessage(content<span style="color:#f92672">=</span>question),
</span></span><span style="display:flex;"><span>           AIMessage(content<span style="color:#f92672">=</span>ai_msg[<span style="color:#e6db74">&#34;answer&#34;</span>]),
</span></span><span style="display:flex;"><span>       ]
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ai_msg[<span style="color:#e6db74">&#34;answer&#34;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pprint <span style="color:#f92672">import</span> pprint
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>    user_input <span style="color:#f92672">=</span> input(<span style="color:#e6db74">&#34;Enter your question: &#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> user_input <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;exit&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        pprint(process_question(user_input))</span></span></code></pre></div>
<p>The output is like</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Enter your question: how does the emperor think about his cloth
</span></span><span style="display:flex;"><span>[outputs]
</span></span><span style="display:flex;"><span>(<span style="color:#e6db74">&#39; order?</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#39;Assistant: The emperor believes that wearing such special clothes will help &#39;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#34;him identify the capable and incapable men in his empire. He&#39;s convinced &#34;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#39;that this material will distinguish the clever from the stupid, and so he &#39;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#39;urgently orders the weavers to begin making the cloth for him.&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Enter your question: how do the emperor<span style="color:#e6db74">&#39;s people think about the emperor</span>
</span></span><span style="display:flex;"><span>[outputs]
</span></span><span style="display:flex;"><span>(<span style="color:#e6db74">&#34;&#39;s cloth?</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#39;AI:  desire and curiosity.</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#34;Assistant: The people in the emperor&#39;s city are intrigued and excited about &#34;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#34;the new fabric. They&#39;ve heard stories about its beauty and the emperor&#39;s &#34;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#39;desire to see it firsthand. This has created a buzz in the community, and &#39;</span>
</span></span><span style="display:flex;"><span> <span style="color:#e6db74">&#39;many are eager to witness the cloth for themselves.&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Enter your question: what was my first question
</span></span><span style="display:flex;"><span>{<span style="color:#e6db74">&#39;output_text&#39;</span>: <span style="color:#e6db74">&#39;The question is: How does the emperor think about his cloth?</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;The final answer is: The emperor thinks about his cloth and &#39;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;wants to see it appear as though it was in his pretty finery.&#39;</span>}
</span></span><span style="display:flex;"><span>Enter your question:</span></span></code></pre></div>
<p>The application retains a record of past conversations and accurately responds to inquiries regarding the initial question posed.</p>
<p>In case you receive the following message:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#39;output_text&#39;</span>: <span style="color:#e6db74">&#39;The passage does not specify how the emperor thinks about his &#39;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;cloth, so I cannot answer this question from the provided &#39;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#39;context.&#39;</span><span style="color:#f92672">}</span></span></span></code></pre></div>
<p>You can run the model with <code>ollama</code>, to trigger the model.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ollama run gemma:2b</span></span></code></pre></div>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Oct 28, 2024
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/langchain_project_book/index.html">
            <div class="logo-title">LangChain AI</div>
          </a>
        </div>
        <search><form action="/langchain_project_book/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/index.html"><a class="padding" href="/langchain_project_book/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/preface/index.html"><a class="padding" href="/langchain_project_book/preface/index.html">Preface</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/index.html"><a class="padding" href="/langchain_project_book/fundamentals/index.html">LangChain Fundamentals</a><ul id="R-subsections-0784c4bcc83cbdf0ace68502ac3215e0" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/index.html">Tools and Libraries</a><ul id="R-subsections-fec951202c7c0f845b2452661e4af48e" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/doc_sum/index.html"><a class="padding" href="/langchain_project_book/doc_sum/index.html">Document Summarization</a><ul id="R-subsections-c75a3cc5095251ebcf3be162192ea6c9" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/index.html">Ticketing System</a><ul id="R-subsections-3f5863c85ccf3c65e662463e67f08191" class="collapsible-menu"></ul></li>
            <li class="parent " data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/index.html">KnowledgeBase Semantic Analysis</a><ul id="R-subsections-c498a6349176744d42feaf82a24933fb" class="collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/arch_n_workflow/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/arch_n_workflow/index.html">Architecture and Workflow</a></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/preparing_data/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/preparing_data/index.html">Preparing Data</a></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/select_embed_model/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/select_embed_model/index.html">Selecting the Embedding Model</a></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/supabase_as_vectorstore/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/supabase_as_vectorstore/index.html">Supabase as VectorStore</a></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/config_llm_with_gemma/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/config_llm_with_gemma/index.html">Configuring LLM with Google Gemma</a></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/enable_multiconv_with_history/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/enable_multiconv_with_history/index.html">Enabling Multi-Round Conversations with Chat History</a></li>
            <li class="active " data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/complete_code/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/complete_code/index.html">Complete Code</a></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/summary/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/summary/index.html">Summary</a></li></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/langchain_project_book/js/clipboard/clipboard.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/perfect-scrollbar/perfect-scrollbar.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/theme.js?1755628295" defer></script>
  </body>
</html>
