<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/langchain_project_book/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=langchain_project_book/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.131.0">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="The architectural components of LangChain, illustrated in Figure 2.1, will be thoroughly explored and discussed in detail throughout the book.
package LangChain { package Agent_Tooling { agent Tools agent Toolkits } package Models_IO { agent Model agent Prompt agent Output_Parser } package Chain_and_Retrieval { agent Retriever agent Document_Loaders agent VectorStore agent TextSplitter agent Embedding_Model } } Chain_and_Retrieval -[hidden] Models_IO Models_IO -[hidden] Agent_Tooling Model -[hidden]- Prompt Prompt -[hidden]- Output_Parser Retriever -[hidden] Document_Loaders Document_Loaders -[hidden]- VectorStore VectorStore -[hidden] TextSplitter TextSplitter -[hidden]- Embedding_Model Tools -[hidden]- Toolkits Figure 2.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="LangChain Architecture :: LangChain AI">
    <meta name="twitter:description" content="The architectural components of LangChain, illustrated in Figure 2.1, will be thoroughly explored and discussed in detail throughout the book.
package LangChain { package Agent_Tooling { agent Tools agent Toolkits } package Models_IO { agent Model agent Prompt agent Output_Parser } package Chain_and_Retrieval { agent Retriever agent Document_Loaders agent VectorStore agent TextSplitter agent Embedding_Model } } Chain_and_Retrieval -[hidden] Models_IO Models_IO -[hidden] Agent_Tooling Model -[hidden]- Prompt Prompt -[hidden]- Output_Parser Retriever -[hidden] Document_Loaders Document_Loaders -[hidden]- VectorStore VectorStore -[hidden] TextSplitter TextSplitter -[hidden]- Embedding_Model Tools -[hidden]- Toolkits Figure 2.">
    <meta property="og:url" content="http://localhost:1313/langchain_project_book/fundamentals/architecture/index.html">
    <meta property="og:site_name" content="LangChain AI">
    <meta property="og:title" content="LangChain Architecture :: LangChain AI">
    <meta property="og:description" content="The architectural components of LangChain, illustrated in Figure 2.1, will be thoroughly explored and discussed in detail throughout the book.
package LangChain { package Agent_Tooling { agent Tools agent Toolkits } package Models_IO { agent Model agent Prompt agent Output_Parser } package Chain_and_Retrieval { agent Retriever agent Document_Loaders agent VectorStore agent TextSplitter agent Embedding_Model } } Chain_and_Retrieval -[hidden] Models_IO Models_IO -[hidden] Agent_Tooling Model -[hidden]- Prompt Prompt -[hidden]- Output_Parser Retriever -[hidden] Document_Loaders Document_Loaders -[hidden]- VectorStore VectorStore -[hidden] TextSplitter TextSplitter -[hidden]- Embedding_Model Tools -[hidden]- Toolkits Figure 2.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="LangChain Fundamentals">
    <meta property="article:published_time" content="2024-10-24T00:10:48-04:00">
    <meta property="article:modified_time" content="2024-10-24T00:10:48-04:00">
    <meta itemprop="name" content="LangChain Architecture :: LangChain AI">
    <meta itemprop="description" content="The architectural components of LangChain, illustrated in Figure 2.1, will be thoroughly explored and discussed in detail throughout the book.
package LangChain { package Agent_Tooling { agent Tools agent Toolkits } package Models_IO { agent Model agent Prompt agent Output_Parser } package Chain_and_Retrieval { agent Retriever agent Document_Loaders agent VectorStore agent TextSplitter agent Embedding_Model } } Chain_and_Retrieval -[hidden] Models_IO Models_IO -[hidden] Agent_Tooling Model -[hidden]- Prompt Prompt -[hidden]- Output_Parser Retriever -[hidden] Document_Loaders Document_Loaders -[hidden]- VectorStore VectorStore -[hidden] TextSplitter TextSplitter -[hidden]- Embedding_Model Tools -[hidden]- Toolkits Figure 2.">
    <meta itemprop="datePublished" content="2024-10-24T00:10:48-04:00">
    <meta itemprop="dateModified" content="2024-10-24T00:10:48-04:00">
    <meta itemprop="wordCount" content="1296">
    <title>LangChain Architecture :: LangChain AI</title>
    <link href="/langchain_project_book/css/auto-complete/auto-complete.min.css?1755628295" rel="stylesheet">
    <script src="/langchain_project_book/js/auto-complete/auto-complete.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/search-lunr.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/search.js?1755628295" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/langchain_project_book/searchindex.en.js?1755628295";
    </script>
    <script src="/langchain_project_book/js/lunr/lunr.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.stemmer.support.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.multi.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/lunr/lunr.en.min.js?1755628295" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/langchain_project_book/fonts/fontawesome/css/fontawesome-all.min.css?1755628295" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/fonts/fontawesome/css/fontawesome-all.min.css?1755628295" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/perfect-scrollbar/perfect-scrollbar.min.css?1755628295" rel="stylesheet">
    <link href="/langchain_project_book/css/theme.css?1755628295" rel="stylesheet">
    <link href="/langchain_project_book/css/format-html.css?1755628295" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/fundamentals\/architecture\/index.html';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/langchain_project_book';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
  </head>
  <body class="mobile-support html" data-url="/langchain_project_book/fundamentals/architecture/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#langchain-workflow">LangChain Workflow</a></li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/langchain_project_book/index.html"><span itemprop="name">LangChain Project Handbook</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/langchain_project_book/fundamentals/index.html"><span itemprop="name">LangChain Fundamentals</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">LangChain Architecture</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/fundamentals/index.html" title="LangChain Fundamentals (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/fundamentals/select_a_right_lm/index.html" title="Select a Right Language Model (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable fundamentals" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="langchain-architecture">LangChain Architecture</h1>

<p>The architectural components of LangChain, illustrated in Figure 2.1, will be thoroughly explored and discussed in detail throughout the book.</p>
<head>
    <script src="https://cdn.jsdelivr.net/gh/jmnote/plantuml-encoder@1.2.4/dist/plantuml-encoder.min.js" integrity="sha256-Qsk2KRBCN5qVZX7B+8+2IvQl1Aqc723qV1tBCQaVoqo=" crossorigin="anonymous"></script>
</head>
<body>
    <pre class="language-plantuml">
    
package LangChain {
    package Agent_Tooling {
        agent Tools
        agent Toolkits
    }
    package Models_IO {
        agent Model
        agent Prompt 
        agent Output_Parser 
    }
    package Chain_and_Retrieval {
        agent Retriever
        agent Document_Loaders
        agent VectorStore
        agent TextSplitter
        agent Embedding_Model
    }
}

Chain_and_Retrieval -[hidden] Models_IO
Models_IO -[hidden] Agent_Tooling

Model -[hidden]- Prompt
Prompt -[hidden]- Output_Parser

Retriever -[hidden] Document_Loaders
Document_Loaders -[hidden]- VectorStore
VectorStore -[hidden] TextSplitter
TextSplitter -[hidden]- Embedding_Model

Tools -[hidden]- Toolkits

    </pre>
    <script>
    (function(){
      let plantumlPrefix = "language-plantuml";
      Array.prototype.forEach.call(document.querySelectorAll("[class^=" + plantumlPrefix + "]"), function(code){
        
        if (!code.previousElementSibling || !code.previousElementSibling.classList.contains('plantuml-image')) {
          let image = document.createElement("IMG");
          image.loading = 'lazy'; 
          image.className = 'plantuml-image'; 
          image.src = 'http://www.plantuml.com/plantuml/svg/~1' + plantumlEncoder.encode(code.innerText);
          code.parentNode.insertBefore(image, code);
          code.style.display = 'none';
        }
      });
    })();
    </script>
</body>
</html>


<p>Figure 2.1: LangChain Architecture</p>
<ul>
<li><strong>Model</strong>: also known as LLM model serve as the core elements of LangChain. They essentially act as wrappers for these models, enabling the utilization of their specific functionalities and capabilities.</li>
<li><strong>Chain</strong>: Chain enables us to integrate multiple components to address a specific task. It streamlines the process of implementing complex applications by enhancing modularity, making debugging and maintenance more straightforward.</li>
<li><strong>Document loaders</strong>: Document Loaders play a role in loading documents into the LangChain system, managing a range of document types like PDFs, and transforming them into a compatible format for LangChain processing. This procedure encompasses multiple stages, including data ingestion, context comprehension, and refinement.</li>
<li><strong>Prompt</strong>: Prompts serve as inputs for LLMs to generate specific responses. Crafting effective prompts is vital for obtaining valuable outputs from LLMs. Prompt engineering aims to create prompts that yield precise, relevant, and beneficial responses from LLMs. For instance, the prompt plays an amazing role in the output when examining the prompt in OpenAI&rsquo;s Sora, which creates stunning and visually striking videos.</li>
<li><strong>VectorStore</strong>: It brings functions for the effective storage and retrieval of vector embeddings. And it operates as a repository for vectors containing supplementary data, streamlining the processes of storage, search, and point management.</li>
<li><strong>Output Parsers</strong>: The <code>output_parser</code> converts the output of an LLM into a more appropriate format, especially beneficial when generating structured data using LLMs.</li>
<li><strong>Agents</strong>: LLMs can communicate with their surroundings through agents. For instance, carrying out a particular task via an external API, or grabbing extra data from outside website.</li>
</ul>
<p>LangChain utilizes a sequential pipeline method to construct tailored applications for LLM. This structured approach integrates diverse services, data inputs, and formatting processes, ensuring accurate processing and consistent output. Modules in LangChain follow a step-by-step process with single inputs and outputs, facilitating smooth data flow. This mechanism simplifies development and enhances LLM utilization. By streamlining workflows, LangChain optimizes AI application development, executing steps in a specific order to real-world processes for managed outcomes.</p>
<h3 id="langchain-workflow">LangChain Workflow</h3>
<p>Having grasped the fundamental elements of LangChain, let&rsquo;s observe its process in detail and how the message is handled. The actual scenarios can change the workflow&rsquo;s logic depending on the requirements. A very common conversation flow is shown in Figure 2.2, which includes <code>document_loaders</code>, data embedding into vectorstore, and query <code>similarity_search</code> within <code>RetrievalQA</code> chain, then returns the analyzed result to the user.</p>
<head>
    <script src="https://cdn.jsdelivr.net/gh/jmnote/plantuml-encoder@1.2.4/dist/plantuml-encoder.min.js" integrity="sha256-Qsk2KRBCN5qVZX7B+8+2IvQl1Aqc723qV1tBCQaVoqo=" crossorigin="anonymous"></script>
</head>
<body>
    <pre class="language-plantuml">
    
actor user
component Load_Docs
component Query
component LLM_generates_answer

package LangChain {
    component Document_Loaders
    component CharacterTextSplitter
    component embeddings
    component PromptTemplate
    component RetrievalQA
}

Load_Docs -> Document_Loaders
user -> Query
Query -> RetrievalQA

Document_Loaders -> CharacterTextSplitter
CharacterTextSplitter --> embeddings
PromptTemplate <- embeddings
PromptTemplate --> RetrievalQA
RetrievalQA -> LLM_generates_answer

Load_Docs -[hidden]- user
Query -[hidden]- LLM_generates_answer

    </pre>
    <script>
    (function(){
      let plantumlPrefix = "language-plantuml";
      Array.prototype.forEach.call(document.querySelectorAll("[class^=" + plantumlPrefix + "]"), function(code){
        
        if (!code.previousElementSibling || !code.previousElementSibling.classList.contains('plantuml-image')) {
          let image = document.createElement("IMG");
          image.loading = 'lazy'; 
          image.className = 'plantuml-image'; 
          image.src = 'http://www.plantuml.com/plantuml/svg/~1' + plantumlEncoder.encode(code.innerText);
          code.parentNode.insertBefore(image, code);
          code.style.display = 'none';
        }
      });
    })();
    </script>
</body>
</html>


<p>Figure 2.2: LangChain Workflow</p>
<!-- raw HTML omitted -->
<p>Let’s discuss these steps in detail. I&rsquo;ve included the Python code for a set of typical modules to demonstrate the components. The real projects will be covered in detail in the upcoming chapters. To run the Python code provided, it is required to set up a working environment, a procedure that will be elaborated on in the upcoming chapter. You can directly proceed to the next chapter to configure your development environment, ensuring the necessary libraries are installed and properly set up for the successful execution of the sample code presented here.</p>
<ul>
<li>
<p><code>document_loaders</code> can load, extract data from diverse sources and transform it into structured documents. It can handle <code>*.txt</code> (plain text) and <code>*.xls</code> (Microsoft Excel), load the HTML content from any website. Here&rsquo;s an example of loading data from Wikipedia through <code>WebBaseLoader</code></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.document_loaders <span style="color:#f92672">import</span> WebBaseLoader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>loader <span style="color:#f92672">=</span> WebBaseLoader(<span style="color:#e6db74">&#34;https://en.wikipedia.org/wiki/Text_file&#34;</span>)
</span></span><span style="display:flex;"><span>document <span style="color:#f92672">=</span> loader<span style="color:#f92672">.</span>load()</span></span></code></pre></div>
</li>
<li>
<p>LangChain uses the <code>TextSplitter</code> class to break down the document into smaller chunks that can be more easily processed by the language model. One of the most used splitters, <code>RecursiveCharacterTextSplitter</code>, divides a large text into chunks based on a defined size, using a set of characters. By default, it utilizes characters like <code>[&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;]</code>, and <code>[&quot;&quot;]</code>. Initially, it attempts to split the text using &ldquo;<code>\n\n</code>&rdquo;. If the resulting chunks are still too large, it progresses to the next character, &ldquo;<code>\n</code>&rdquo;, for further splitting. This process continues through the set of characters until a split smaller than the specified chunk size is achieved. The <code>chunk_size</code> parameter controls the max size of the final documents, and the <code>chunk_overlap</code> parameter specifies how much overlap there should be between chunks.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.text_splitter <span style="color:#f92672">import</span> RecursiveCharacterTextSplitter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>splitter <span style="color:#f92672">=</span> RecursiveCharacterTextSplitter(chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>, chunk_overlap<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>)
</span></span><span style="display:flex;"><span>docs <span style="color:#f92672">=</span> splitter<span style="color:#f92672">.</span>split_documents(document)</span></span></code></pre></div>
</li>
<li>
<p>LangChain uses a VectorStore to create <code>embeddings</code> for each document split. These <code>embeddings</code> are numerical representations of the text that can be used for efficient information retrieval. The provided code snippet utilizes the <code>all-mpnet-base-v2</code> model from <code>HuggingFaceEmbeddings</code> by default. If not explicitly specified, this model is used. Additionally, the code operates with a vector store based on Qdrant, running in memory. (Please be aware that the vector store we have just set up operates in memory, which implies that all data will be lost when your computer is turned off. The advantage of utilizing a memory-based vector store is the ability to swiftly test your code without the need to save it. We will delve into persistent storage for production purposes in upcoming chapters). The collection is named <code>wikipedia</code> in vectorstore.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_huggingface <span style="color:#f92672">import</span> HuggingFaceEmbeddings
</span></span><span style="display:flex;"><span>model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;sentence-transformers/all-mpnet-base-v2&#34;</span>
</span></span><span style="display:flex;"><span>model_kwargs <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;device&#39;</span>: <span style="color:#e6db74">&#39;cpu&#39;</span>}
</span></span><span style="display:flex;"><span>encode_kwargs <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;normalize_embeddings&#39;</span>: <span style="color:#66d9ef">True</span>}
</span></span><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> HuggingFaceEmbeddings(
</span></span><span style="display:flex;"><span>    model_name <span style="color:#f92672">=</span> model_name,
</span></span><span style="display:flex;"><span>    model_kwargs <span style="color:#f92672">=</span> model_kwargs,
</span></span><span style="display:flex;"><span>    encode_kwargs <span style="color:#f92672">=</span> encode_kwargs,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.vectorstores <span style="color:#f92672">import</span> Qdrant
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vectorstore <span style="color:#f92672">=</span> Qdrant<span style="color:#f92672">.</span>from_documents(
</span></span><span style="display:flex;"><span>    docs,
</span></span><span style="display:flex;"><span>    embedding <span style="color:#f92672">=</span> embedding,
</span></span><span style="display:flex;"><span>    location <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;:memory:&#34;</span>,
</span></span><span style="display:flex;"><span>    collection_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;wikipedia&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>print(vectorstore)</span></span></code></pre></div>
</li>
<li>
<p>Subsequently, the VectorStore is employed to conduct a <code>similarity_search</code> on the document embeddings, aiming to identify the documents most pertinent to the user&rsquo;s query. The search provides relevance scores for the query and outputs 2 results.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;What&#39;s flatfile?&#34;</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> vectorstore<span style="color:#f92672">.</span>similarity_search_with_score(query, k<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>print(result)</span></span></code></pre></div>
</li>
<li>
<p>To make foundation models useful for domain-specific tasks, the Retrieval Augmented Generation (RAG) framework augments prompts with external data from multiple sources, including document repositories, databases, or APIs. In a later chapter, we will examine how RAG functions in actual projects. For the time being, this is a brief excerpt of RAG code that illustrates how retrieval functions to obtain data from vectorstore using meaning rather than keywords.</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;What is flatfile?&#34;</span>
</span></span><span style="display:flex;"><span>retriever <span style="color:#f92672">=</span> vectorstore<span style="color:#f92672">.</span>as_retriever()
</span></span><span style="display:flex;"><span>print(retriever<span style="color:#f92672">.</span>get_relevant_documents(query)[<span style="color:#ae81ff">0</span>])</span></span></code></pre></div>
</li>
</ul>
<p>The entire code, for instance, looks like this:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> bs4 <span style="color:#f92672">import</span> BeautifulSoup
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.document_loaders <span style="color:#f92672">import</span> WebBaseLoader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>loader <span style="color:#f92672">=</span> WebBaseLoader(<span style="color:#e6db74">&#34;https://en.wikipedia.org/wiki/Text_file&#34;</span>)
</span></span><span style="display:flex;"><span>document <span style="color:#f92672">=</span> loader<span style="color:#f92672">.</span>load()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.text_splitter <span style="color:#f92672">import</span> RecursiveCharacterTextSplitter
</span></span><span style="display:flex;"><span>splitter <span style="color:#f92672">=</span> RecursiveCharacterTextSplitter(chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>, chunk_overlap<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>)
</span></span><span style="display:flex;"><span>docs <span style="color:#f92672">=</span> splitter<span style="color:#f92672">.</span>split_documents(document)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_huggingface <span style="color:#f92672">import</span> HuggingFaceEmbeddings
</span></span><span style="display:flex;"><span>model_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;sentence-transformers/all-mpnet-base-v2&#34;</span>
</span></span><span style="display:flex;"><span>model_kwargs <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;device&#39;</span>: <span style="color:#e6db74">&#39;cpu&#39;</span>}
</span></span><span style="display:flex;"><span>encode_kwargs <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;normalize_embeddings&#39;</span>: <span style="color:#66d9ef">True</span>}
</span></span><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> HuggingFaceEmbeddings(
</span></span><span style="display:flex;"><span>    model_name <span style="color:#f92672">=</span> model_name,
</span></span><span style="display:flex;"><span>    model_kwargs <span style="color:#f92672">=</span> model_kwargs,
</span></span><span style="display:flex;"><span>    encode_kwargs <span style="color:#f92672">=</span> encode_kwargs,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.vectorstores <span style="color:#f92672">import</span> Qdrant
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vectorstore <span style="color:#f92672">=</span> Qdrant<span style="color:#f92672">.</span>from_documents(
</span></span><span style="display:flex;"><span>    docs,
</span></span><span style="display:flex;"><span>    embedding <span style="color:#f92672">=</span> embedding,
</span></span><span style="display:flex;"><span>    location <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;:memory:&#34;</span>,
</span></span><span style="display:flex;"><span>    collection_name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;wikipedia&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>query <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;What&#39;s flatfile?&#34;</span>
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> vectorstore<span style="color:#f92672">.</span>similarity_search_with_score(query, k<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>retriever <span style="color:#f92672">=</span> vectorstore<span style="color:#f92672">.</span>as_retriever()
</span></span><span style="display:flex;"><span>print(retriever<span style="color:#f92672">.</span>get_relevant_documents(query)[<span style="color:#ae81ff">0</span>])</span></span></code></pre></div>
<p>The above code snippet goes through the following steps to process the document</p>
<ul>
<li>Load a document, and split it into smaller chunks</li>
<li>Insert the splitted chunks into VectoreStore, which is configured as running in memory. You may want to persist it in production</li>
<li>Create a query, then send it to VectorStore for similarity_search</li>
<li>Retrieve the relevant document</li>
</ul>
<p>The flow is straight forward and simple. The code in the previous example follows a fundamental flow, incorporating VectorStore with embeddings but not yet involving LLM. Our next step is to introduce an LLM into the process.</p>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Oct 24, 2024
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/langchain_project_book/index.html">
            <div class="logo-title">LangChain AI</div>
          </a>
        </div>
        <search><form action="/langchain_project_book/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/index.html"><a class="padding" href="/langchain_project_book/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/preface/index.html"><a class="padding" href="/langchain_project_book/preface/index.html">Preface</a></li>
            <li class="parent " data-nav-id="/langchain_project_book/fundamentals/index.html"><a class="padding" href="/langchain_project_book/fundamentals/index.html">LangChain Fundamentals</a><ul id="R-subsections-0784c4bcc83cbdf0ace68502ac3215e0" class="collapsible-menu">
            <li class="active " data-nav-id="/langchain_project_book/fundamentals/architecture/index.html"><a class="padding" href="/langchain_project_book/fundamentals/architecture/index.html">LangChain Architecture</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/select_a_right_lm/index.html"><a class="padding" href="/langchain_project_book/fundamentals/select_a_right_lm/index.html">Select a Right Language Model</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/llm_settings_n_limits/index.html"><a class="padding" href="/langchain_project_book/fundamentals/llm_settings_n_limits/index.html">LLM Settings and Limits</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/thoughts_on_prompt/index.html"><a class="padding" href="/langchain_project_book/fundamentals/thoughts_on_prompt/index.html">Thoughts on Prompt Engineering</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html"><a class="padding" href="/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html">Embeddings and VectorStore</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/chains_n_retriever/index.html"><a class="padding" href="/langchain_project_book/fundamentals/chains_n_retriever/index.html">Chains and Retriever</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/document_n_debugging/index.html"><a class="padding" href="/langchain_project_book/fundamentals/document_n_debugging/index.html">Document and Debugging</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/summary/index.html"><a class="padding" href="/langchain_project_book/fundamentals/summary/index.html">Summary</a></li></ul></li>
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/index.html">Tools and Libraries</a><ul id="R-subsections-fec951202c7c0f845b2452661e4af48e" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/doc_sum/index.html"><a class="padding" href="/langchain_project_book/doc_sum/index.html">Document Summarization</a><ul id="R-subsections-c75a3cc5095251ebcf3be162192ea6c9" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/index.html">Ticketing System</a><ul id="R-subsections-3f5863c85ccf3c65e662463e67f08191" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/index.html">KnowledgeBase Semantic Analysis</a><ul id="R-subsections-c498a6349176744d42feaf82a24933fb" class="collapsible-menu"></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/langchain_project_book/js/clipboard/clipboard.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/perfect-scrollbar/perfect-scrollbar.min.js?1755628295" defer></script>
    <script src="/langchain_project_book/js/theme.js?1755628295" defer></script>
  </body>
</html>
