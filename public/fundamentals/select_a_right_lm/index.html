<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article">
  <head><script src="/langchain_project_book/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=langchain_project_book/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.134.2">
    <meta name="generator" content="Relearn 7.0.1+72a875f1db967152c77914cff4d53f8fcee0e619">
    <meta name="description" content="When selecting a language model and an embedding model in LangChain technology, there are several things to consider:
Primary Task: Identify the core functions of the language model (LLM), which include tasks like text generation, summarization, translation, and answering queries. A valuable resource to explore these tasks is https://huggingface.co/models covering a wide range from Multimodal to Computer Vision (CV) and Natural Language Processing (NLP). Common examples in this context involve Summarization, Text Generation, and Question Answering within NLP.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Select a Right Language Model :: LangChain AI">
    <meta name="twitter:description" content="When selecting a language model and an embedding model in LangChain technology, there are several things to consider:
Primary Task: Identify the core functions of the language model (LLM), which include tasks like text generation, summarization, translation, and answering queries. A valuable resource to explore these tasks is https://huggingface.co/models covering a wide range from Multimodal to Computer Vision (CV) and Natural Language Processing (NLP). Common examples in this context involve Summarization, Text Generation, and Question Answering within NLP.">
    <meta property="og:url" content="http://localhost:1313/langchain_project_book/fundamentals/select_a_right_lm/index.html">
    <meta property="og:site_name" content="LangChain AI">
    <meta property="og:title" content="Select a Right Language Model :: LangChain AI">
    <meta property="og:description" content="When selecting a language model and an embedding model in LangChain technology, there are several things to consider:
Primary Task: Identify the core functions of the language model (LLM), which include tasks like text generation, summarization, translation, and answering queries. A valuable resource to explore these tasks is https://huggingface.co/models covering a wide range from Multimodal to Computer Vision (CV) and Natural Language Processing (NLP). Common examples in this context involve Summarization, Text Generation, and Question Answering within NLP.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="LangChain Fundamentals">
    <meta property="article:published_time" content="2024-10-28T17:52:48+08:00">
    <meta property="article:modified_time" content="2024-10-28T17:52:48+08:00">
    <meta itemprop="name" content="Select a Right Language Model :: LangChain AI">
    <meta itemprop="description" content="When selecting a language model and an embedding model in LangChain technology, there are several things to consider:
Primary Task: Identify the core functions of the language model (LLM), which include tasks like text generation, summarization, translation, and answering queries. A valuable resource to explore these tasks is https://huggingface.co/models covering a wide range from Multimodal to Computer Vision (CV) and Natural Language Processing (NLP). Common examples in this context involve Summarization, Text Generation, and Question Answering within NLP.">
    <meta itemprop="datePublished" content="2024-10-28T17:52:48+08:00">
    <meta itemprop="dateModified" content="2024-10-28T17:52:48+08:00">
    <meta itemprop="wordCount" content="1470">
    <title>Select a Right Language Model :: LangChain AI</title>
    <link href="/langchain_project_book/css/fontawesome-all.min.css?1731235150" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/fontawesome-all.min.css?1731235150" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/nucleus.css?1731235150" rel="stylesheet">
    <link href="/langchain_project_book/css/auto-complete.css?1731235150" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/auto-complete.css?1731235150" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/perfect-scrollbar.min.css?1731235150" rel="stylesheet">
    <link href="/langchain_project_book/css/fonts.css?1731235150" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/fonts.css?1731235150" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/theme.css?1731235150" rel="stylesheet">
    <link href="/langchain_project_book/css/theme-auto.css?1731235150" rel="stylesheet" id="R-variant-style">
    <link href="/langchain_project_book/css/chroma-auto.css?1731235150" rel="stylesheet" id="R-variant-chroma-style">
    <link href="/langchain_project_book/css/print.css?1731235150" rel="stylesheet" media="print">
    <script src="/langchain_project_book/js/variant.js?1731235150"></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/langchain_project_book';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      // variant stuff
      window.variants && variants.init( [ 'auto' ] );
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script>
  </head>
  <body class="mobile-support html" data-url="/langchain_project_book/fundamentals/select_a_right_lm/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#some-models-with-my-experience">Some Models with My Experience</a></li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/langchain_project_book/index.html"><span itemprop="name">LangChain Project Handbook</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/langchain_project_book/fundamentals/index.html"><span itemprop="name">LangChain Fundamentals</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><span itemprop="name">Select a Right Language Model</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/fundamentals/architecture/index.html" title="LangChain Architecture (ðŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/fundamentals/llm_settings_n_limits/index.html" title="LLM Settings and Limits (ðŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable fundamentals" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="select-a-right-language-model">Select a Right Language Model</h1>

<p>When selecting a language model and an embedding model in LangChain technology, there are several things to consider:</p>
<ul>
<li>
<p><strong>Primary Task</strong>: Identify the core functions of the language model (LLM), which include tasks like text generation, summarization, translation, and answering queries. A valuable resource to explore these tasks is <a href="https://huggingface.co/models" rel="external" target="_blank">https://huggingface.co/models</a> covering a wide range from Multimodal to Computer Vision (CV) and Natural Language Processing (NLP). Common examples in this context involve Summarization, Text Generation, and Question Answering within NLP.</p>
</li>
<li>
<p><strong>Model Size</strong>: The size of LLMs can vary significantly, with models ranging from millions to billions of parameters. Larger models typically offer better performance but are also more computationally expensive.</p>
</li>
<li>
<p><strong>Pre-Trained vs. Fine-Tuned</strong>: Fine-tuned models are designed specifically for a given task or domain, whereas pre-trained models are appropriate for a variety of tasks. Based on my practical experience, fine-tuning a custom model in a real project is not as straightforward as anticipated in theory. The objective of fine-tuning is to train a customized model using a base model like Llama2. The main challenge lies in the difficulty of curating a dataset of sufficient quality and quantity, which is not a simple work, to effectively train a domain-specific model.
One of my projects entailed training a renowned novel (the dataset comprises all content of the novel and numerous comments carefully chosen for their guaranteed quality) using multiple base models, notably llama2. We dedicated four weeks to curate up to 10,000 question-answer pairs (not enough obviously) before inputting them into the base model for training. Due to the novel-specific nature of these QA pairs, ensuring their accuracy and quality through thorough review proved to be quite time-consuming with a certain level of knowledge required. Unfortunately, the model&rsquo;s performance post-training fell short of expectations, likely due to our supplied data being buried within the generic framework of the base model, which is typically tailored for broader applications rather than domain-specific tasks. Instead of fine-tuning your own model, I would suggest considering retrieval augmented generation (RAG) due to its advantages in query quality, performance, and task flexibility.</p>
</li>
<li>
<p><strong>Accuracy</strong>: The model you select should have excellent performance and accuracy.
Within this book, I have endeavored to explore and evaluate about 10 distinct open-source language models using LangChain, drawing from my personal experiences across various projects. This approach aims to provide firsthand experience to Language Learning Models (LLMs), encompassing models like Mistral, Llama2, Gemma, Flan, and GPT-2. I will systematically delve into each model with accompanying code examples for a comprehensive understanding.</p>
</li>
<li>
<p><strong>Integration</strong>: To facilitate the integration of the model into your current systems, search for an LLM provider that provides user-friendly APIs or SDKs. As an illustration, consider Google&rsquo;s <code>Gemma</code> model, which was unveiled in early 2024. To explore its integration with Transformers, you can refer to <a href="https://huggingface.co/google/gemma-7b?library=true" rel="external" target="_blank">https://huggingface.co/google/gemma-7b?library=true</a> . This resource demonstrates the straightforward process of integrating Gemma into a Python library.</p>
</li>
<li>
<p><strong>Scalability</strong>: The model you select should be able to handle the amount of data you intend to process, especially if you require large-scale real-time responses.</p>
</li>
<li>
<p><strong>Cost</strong>: Understand the pricing model, which could be influenced by factors like token quantity, API usage, or computational hours, as seen in platforms like OpenAI. In this book, the language models employed in this guide will be entirely open source. This means they are technically free to utilize, offering an alternative to services like OpenAI.</p>
</li>
<li>
<p><strong>Storage</strong>: In terms of storage, options like ElasticSearch, FAISS, or Qdrant can be used based on your specific requirements. FAISS, for example, is fast due to its GPU support but requires you to maintain your metadata information separately in some database with mapping of your FAISS ids. For long documents, it&rsquo;s useful to split the document into multiple sections if your transformer model has a context length limit (such as 512 tokens), and each section corresponds to its own vector.</p>
</li>
</ul>
<p>Again, I will explore the open-source language models featured in this guide, accessible at <a href="https://huggingface.co" rel="external" target="_blank">https://huggingface.co</a></p>
<p>In conclusion, the precise tasks you need to complete, the model&rsquo;s size, its accuracy, ease of integration, scalability, cost, and the kind of semantic search you&rsquo;re using will all influence your choice of LLM. It&rsquo;s worthwhile to regularly visit <a href="https://huggingface.co/models" rel="external" target="_blank">https://huggingface.co/models</a> to explore its playground and select a model that fits your real-world situation.</p>
<h3 id="some-models-with-my-experience">Some Models with My Experience</h3>
<p>I have been a part of various genuine customer interactions where we delved into discussions regarding the design conversation flow and business situations. The LangChain framework serves as the backbone for crafting project designs, and I&rsquo;m eager to impart some insights I have gained from these experiences. These lessons, drawn from real-world projects, offer valuable perspectives, such as collecting raw data, choosing appropriate LLMs, customizing prompt(s) and establishing a precise chain to handle communication.</p>
<ul>
<li>
<p><strong>Mistral 7B</strong> stands as a cutting-edge 7.3 billion parameter language model, marking a significant leap in the realm of large language models (LLMs). It has surpassed the performance of the 13 billion parameter Llama 2 model across all tasks and excels over the 34 billion parameter Llama 1 on numerous benchmarks.
Undoubtedly, this model ranks among the top-tier open-source LLMs I have utilized in LangChain development projects, offering impressive performance while demanding reasonable computational resources (such as a GPU with 16GB memory like an NVIDIA RTX 4090). Its strengths lie in performance, orchestration flexibility, accuracy, competitiveness, and comparison with services like OpenAI. This book primarily showcases code examples focused on the Mistral LLM, conveniently packaged by GPT4All and Ollama for easy use. I love this model.</p>
</li>
<li>
<p><strong>FLAN-T5</strong> is a publicly available, extensive language model designed for sequence-to-sequence tasks, suitable for commercial applications. Developed by Google researchers towards the end of 2022, this model has undergone fine-tuning across diverse tasks. The T5 model restructures different tasks into a text-to-text framework, encompassing activities like translation, linguistic evaluation, sentence comparison, and document condensation. FLAN represents &ldquo;Fine-tuned LAnguage Net,&rdquo; while T-5 stands for &ldquo;Text-To-Text Transfer Transformer.&rdquo;</p>
</li>
<li>
<p><strong>Llama2</strong>: Llama-2 is free to download, but Meta requires a register to grant us access to this model&rsquo;s family with additional commercial terms. The request is made through a Meta Webpage, which can be accessed from the model homepage on Hugging Face. You can use it as the base to train your own model with fine-tuning.</p>
</li>
<li>
<p><strong>GPT-2</strong>: The GPT-2 model, a formidable transformer-based language model with 1.5 billion parameters, was trained using a dataset of 8 million web pages. Its primary training goal is to predict the next word by considering all preceding words in a text. The diverse nature of the dataset ensures that this fundamental objective covers genuine instances of numerous tasks across various fields. GPT-2 stands as a notable improvement over its forerunner, GPT, with more than ten times the parameters and trained on over ten times the data volume.</p>
</li>
<li>
<p><strong>MiniLM</strong>: You can find the details by searchingâ€¯<code>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2</code>â€¯or <code>sentence-transformers/all-mpnet-base-v2</code> at <a href="https://huggingface.co/sentence-transformers" rel="external" target="_blank">https://huggingface.co/sentence-transformers</a> . It can be used for tasks like clustering embedding or semantic similarity search. Throughout this guide, we will utilize these models for embedding with the VectorStore.</p>
</li>
<li>
<p><strong>Gemma</strong>: a series of cutting-edge open models, is derived from Gemini&rsquo;s technology. With options of 2 billion and 7 billion parameters, Gemma demonstrates superior performance in language tasks and safety assessments, outperforming competitors in 11 out of 18 text-based tasks. The project prioritizes responsible deployment of LLMs to improve safety and drive innovation. Gemma&rsquo;s lightweight design and open-source approach position it as a significant advancement in LLMs. Weâ€™re going to use <code>gemma-2b</code> model in next chapters. The model can be found at <a href="https://huggingface.co/google/gemma-2b" rel="external" target="_blank">https://huggingface.co/google/gemma-2b</a></p>
</li>
<li>
<p><strong><code>t5-base-finetuned-wikiSQL</code></strong>:â€¯I found this one intriguing from Hugging Face and used this model to generate translate userâ€™s instruction in text into SQL. Hereâ€™s  and give a snippet of code as example: (To run the Python code provided, it is crucial to prepare a functional environment, a process that will be elaborated on in the subsequent chapter. You may find it beneficial to proceed directly to that chapter to set up the necessary environment for running the code.)</p>
<div class="highlight wrap-code"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#f92672">from</span> pprint <span style="color:#f92672">import</span> pprint
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.llms <span style="color:#f92672">import</span> HuggingFaceHub
</span></span><span style="display:flex;"><span>llm <span style="color:#f92672">=</span> HuggingFaceHub(repo_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;mrm8488/t5-base-finetuned-wikiSQL&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain.prompts <span style="color:#f92672">import</span> PromptTemplate
</span></span><span style="display:flex;"><span>prompt <span style="color:#f92672">=</span> PromptTemplate(
</span></span><span style="display:flex;"><span>    input_variables<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;question&#34;</span>],
</span></span><span style="display:flex;"><span>    template<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Translate English to SQL: </span><span style="color:#e6db74">{question}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_core.runnables <span style="color:#f92672">import</span> RunnableLambda
</span></span><span style="display:flex;"><span>chain <span style="color:#f92672">=</span> prompt <span style="color:#f92672">|</span> llm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pprint(chain<span style="color:#f92672">.</span>invoke(<span style="color:#e6db74">&#34;What is the average age of the respondents using a mobile device?&#34;</span>))
</span></span><span style="display:flex;"><span>pprint(chain<span style="color:#f92672">.</span>invoke(<span style="color:#e6db74">&#34;What is the median  age of the respondents using a mobile device?&#34;</span>))</span></span></code></pre></div>
<p>The output shows a SQL generated from <code>t5-base-finetuned-wikiSQL</code> model, which is fine-tuned from Googleâ€™s T5</p>
<div class="highlight wrap-code"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>&gt; Entering new LLMChain chain...
</span></span><span style="display:flex;"><span>Prompt after formatting:
</span></span><span style="display:flex;"><span>Translate English to SQL: What is the median  age of the respondents using a mobile device?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>&gt; Finished chain.
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#39;question&#39;</span>: <span style="color:#e6db74">&#39;What is the median  age of the respondents using a mobile &#39;</span>
</span></span><span style="display:flex;"><span>             <span style="color:#e6db74">&#39;device?&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#e6db74">&#39;text&#39;</span>: <span style="color:#e6db74">&#39;SELECT Median age (years) FROM table WHERE Device = mobile&#39;</span><span style="color:#f92672">}</span></span></span></code></pre></div>
</li>
</ul>
<p>After reviewing a variety of language models from numerous open-source repositories, let&rsquo;s delve into understanding how to configure the typical and widely used settings of these models.</p>

  <footer class="footline">
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/langchain_project_book/index.html">
LangChain AI
          </a>
        </div>
        <script>
          window.index_js_url="/langchain_project_book/searchindex.js?1731235150";
        </script>
        <search><form action="/langchain_project_book/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
        <script>
          var contentLangs=['en'];
        </script>
        <script src="/langchain_project_book/js/auto-complete.js?1731235150" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.min.js?1731235150" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.stemmer.support.min.js?1731235150" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.multi.min.js?1731235150" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.en.min.js?1731235150" defer></script>
        <script src="/langchain_project_book/js/search.js?1731235150" defer></script>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <ul>
          <li><a class="padding" href="/langchain_project_book/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
        </ul>
        <hr class="padding">
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div id="R-topics">
          <ul class="enlarge morespace collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/preface/index.html"><a class="padding" href="/langchain_project_book/preface/index.html">Preface</a></li>
            <li class="parent " data-nav-id="/langchain_project_book/fundamentals/index.html"><a class="padding" href="/langchain_project_book/fundamentals/index.html">LangChain Fundamentals</a><ul id="R-subsections-c6757c34957c6808b13ecd5148aeca96" class="collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/fundamentals/architecture/index.html"><a class="padding" href="/langchain_project_book/fundamentals/architecture/index.html">LangChain Architecture</a></li>
            <li class="active " data-nav-id="/langchain_project_book/fundamentals/select_a_right_lm/index.html"><a class="padding" href="/langchain_project_book/fundamentals/select_a_right_lm/index.html">Select a Right Language Model</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/llm_settings_n_limits/index.html"><a class="padding" href="/langchain_project_book/fundamentals/llm_settings_n_limits/index.html">LLM Settings and Limits</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/thoughts_on_prompt/index.html"><a class="padding" href="/langchain_project_book/fundamentals/thoughts_on_prompt/index.html">Thoughts on Prompt Engineering</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html"><a class="padding" href="/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html">Embeddings and VectorStore</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/chains_n_retriever/index.html"><a class="padding" href="/langchain_project_book/fundamentals/chains_n_retriever/index.html">Chains and Retriever</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/document_n_debugging/index.html"><a class="padding" href="/langchain_project_book/fundamentals/document_n_debugging/index.html">Document and Debugging</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/summary/index.html"><a class="padding" href="/langchain_project_book/fundamentals/summary/index.html">Summary</a></li></ul></li>
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/index.html">Tools and Libraries</a><ul id="R-subsections-cc34bf23dab60f9112ee939495610dcf" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/doc_sum/index.html"><a class="padding" href="/langchain_project_book/doc_sum/index.html">Document Summarization</a><ul id="R-subsections-76bbd5376befb633d2052d0ea4508ef3" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/index.html">Ticketing System</a><ul id="R-subsections-eaa6b154ff31d8e1af72e9555a67f96a" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/index.html">KnowledgeBase Semantic Analysis</a><ul id="R-subsections-c718aa372d1e4f26c29659df75d5d07f" class="collapsible-menu"></ul></li>
          </ul>
        </div>
        <div class="padding footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div>
        <div id="R-menu-footer">
          <hr class="padding default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter">
          <div id="R-prefooter" class="footerLangSwitch footerVariantSwitch footerVisitedLinks">
            <ul>
              <li id="R-select-language-container" class="footerLangSwitch">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-language"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <label class="a11y-only" for="R-select-language">Language</label>
                    <select id="R-select-language" onchange="location = this.querySelector( this.value ).dataset.url;">
                      <option id="R-select-language-en" value="#R-select-language-en" data-url="/langchain_project_book/fundamentals/select_a_right_lm/index.html" lang="en-us" selected></option>
                    </select>
                  </div>
                  <div class="clear"></div>
                </div>
              </li>
              <li id="R-select-variant-container" class="footerVariantSwitch">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-paint-brush"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <label class="a11y-only" for="R-select-variant">Theme</label>
                    <select id="R-select-variant" onchange="window.variants && variants.changeVariant( this.value );">
                      <option id="R-select-variant-auto" value="auto" selected>Auto</option>
                    </select>
                  </div>
                  <div class="clear"></div>
                </div>
                <script>window.variants && variants.markSelectedVariant();</script>
              </li>
              <li class="footerVisitedLinks">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-history"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <button onclick="clearHistory();">Clear History</button>
                  </div>
                  <div class="clear"></div>
                </div>
              </li>
            </ul>
          </div>
          <div id="R-footer" class="footerFooter showFooter">
        <p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p>
          </div>
        </div>
      </div>
    </aside>
    <script src="/langchain_project_book/js/clipboard.min.js?1731235150" defer></script>
    <script src="/langchain_project_book/js/perfect-scrollbar.min.js?1731235150" defer></script>
    <script src="/langchain_project_book/js/theme.js?1731235150" defer></script>
  </body>
</html>
