<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article">
  <head><script src="/langchain_project_book/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=langchain_project_book/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.134.2">
    <meta name="generator" content="Relearn 7.0.1+72a875f1db967152c77914cff4d53f8fcee0e619">
    <meta name="description" content="In LangChain, a Python library designed to simplify the process of building Natural Language Processing (NLP) applications using LLMs, embeddings and VectorStore play a crucial role in enhancing the accuracy and efficiency of these applications.
Understanding Embeddings In the realm of LLMs, embeddings serve as numeric depictions of words, phrases, or sentences, encapsulating their semantic meaning and context. These embeddings facilitate text representation in a machine-learning-friendly format, supporting a range of NLP endeavors. Commonly pretrained on vast text datasets, embeddings such as Word2Vec, GloVe, and FastText capture semantic connections and resemblances among words. By converting words into vectors, these embeddings streamline tasks like text analysis and generation, empowering models to comprehend and handle language proficiently by leveraging contextual cues.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Embeddings and VectorStore :: LangChain AI">
    <meta name="twitter:description" content="In LangChain, a Python library designed to simplify the process of building Natural Language Processing (NLP) applications using LLMs, embeddings and VectorStore play a crucial role in enhancing the accuracy and efficiency of these applications.
Understanding Embeddings In the realm of LLMs, embeddings serve as numeric depictions of words, phrases, or sentences, encapsulating their semantic meaning and context. These embeddings facilitate text representation in a machine-learning-friendly format, supporting a range of NLP endeavors. Commonly pretrained on vast text datasets, embeddings such as Word2Vec, GloVe, and FastText capture semantic connections and resemblances among words. By converting words into vectors, these embeddings streamline tasks like text analysis and generation, empowering models to comprehend and handle language proficiently by leveraging contextual cues.">
    <meta property="og:url" content="http://localhost:1313/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html">
    <meta property="og:site_name" content="LangChain AI">
    <meta property="og:title" content="Embeddings and VectorStore :: LangChain AI">
    <meta property="og:description" content="In LangChain, a Python library designed to simplify the process of building Natural Language Processing (NLP) applications using LLMs, embeddings and VectorStore play a crucial role in enhancing the accuracy and efficiency of these applications.
Understanding Embeddings In the realm of LLMs, embeddings serve as numeric depictions of words, phrases, or sentences, encapsulating their semantic meaning and context. These embeddings facilitate text representation in a machine-learning-friendly format, supporting a range of NLP endeavors. Commonly pretrained on vast text datasets, embeddings such as Word2Vec, GloVe, and FastText capture semantic connections and resemblances among words. By converting words into vectors, these embeddings streamline tasks like text analysis and generation, empowering models to comprehend and handle language proficiently by leveraging contextual cues.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="LangChain Fundamentals">
    <meta property="article:published_time" content="2024-10-28T18:17:09+08:00">
    <meta property="article:modified_time" content="2024-10-28T18:17:09+08:00">
    <meta itemprop="name" content="Embeddings and VectorStore :: LangChain AI">
    <meta itemprop="description" content="In LangChain, a Python library designed to simplify the process of building Natural Language Processing (NLP) applications using LLMs, embeddings and VectorStore play a crucial role in enhancing the accuracy and efficiency of these applications.
Understanding Embeddings In the realm of LLMs, embeddings serve as numeric depictions of words, phrases, or sentences, encapsulating their semantic meaning and context. These embeddings facilitate text representation in a machine-learning-friendly format, supporting a range of NLP endeavors. Commonly pretrained on vast text datasets, embeddings such as Word2Vec, GloVe, and FastText capture semantic connections and resemblances among words. By converting words into vectors, these embeddings streamline tasks like text analysis and generation, empowering models to comprehend and handle language proficiently by leveraging contextual cues.">
    <meta itemprop="datePublished" content="2024-10-28T18:17:09+08:00">
    <meta itemprop="dateModified" content="2024-10-28T18:17:09+08:00">
    <meta itemprop="wordCount" content="719">
    <title>Embeddings and VectorStore :: LangChain AI</title>
    <link href="/langchain_project_book/css/fontawesome-all.min.css?1730158732" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/fontawesome-all.min.css?1730158732" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/nucleus.css?1730158732" rel="stylesheet">
    <link href="/langchain_project_book/css/auto-complete.css?1730158732" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/auto-complete.css?1730158732" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/perfect-scrollbar.min.css?1730158732" rel="stylesheet">
    <link href="/langchain_project_book/css/fonts.css?1730158732" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/langchain_project_book/css/fonts.css?1730158732" rel="stylesheet"></noscript>
    <link href="/langchain_project_book/css/theme.css?1730158732" rel="stylesheet">
    <link href="/langchain_project_book/css/theme-auto.css?1730158732" rel="stylesheet" id="R-variant-style">
    <link href="/langchain_project_book/css/chroma-auto.css?1730158732" rel="stylesheet" id="R-variant-chroma-style">
    <link href="/langchain_project_book/css/print.css?1730158732" rel="stylesheet" media="print">
    <script src="/langchain_project_book/js/variant.js?1730158732"></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/langchain_project_book';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      // variant stuff
      window.variants && variants.init( [ 'auto' ] );
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
    </script>
  </head>
  <body class="mobile-support html" data-url="/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper"> 
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/langchain_project_book/index.html"><span itemprop="name">LangChain Project Handbook</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><a itemprop="item" href="/langchain_project_book/fundamentals/index.html"><span itemprop="name">LangChain Fundamentals</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li
            itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><span itemprop="name">Embeddings and VectorStore</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/fundamentals/thoughts_on_prompt/index.html" title="Thoughts on Prompt Engineering (ðŸ¡)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/langchain_project_book/fundamentals/chains_n_retriever/index.html" title="Chains and Retriever (ðŸ¡’)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable fundamentals" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="embeddings-and-vectorstore">Embeddings and VectorStore</h1>

<p>In LangChain, a Python library designed to simplify the process of building Natural Language Processing (NLP) applications using LLMs, embeddings and VectorStore play a crucial role in enhancing the accuracy and efficiency of these applications.</p>
<h4 id="understanding-embeddings">Understanding Embeddings</h4>
<p>In the realm of LLMs, embeddings serve as numeric depictions of words, phrases, or sentences, encapsulating their semantic meaning and context. These embeddings facilitate text representation in a machine-learning-friendly format, supporting a range of NLP endeavors. Commonly pretrained on vast text datasets, embeddings such as Word2Vec, GloVe, and FastText capture semantic connections and resemblances among words. By converting words into vectors, these embeddings streamline tasks like text analysis and generation, empowering models to comprehend and handle language proficiently by leveraging contextual cues.</p>
<p>I recommend dedicating some time to review an insightful document authored by Sascha Metzger, which elaborates on tokens, vectors, and embeddings in the field of natural language processing. The document can be accessed at <a href="https://saschametzger.com/blog/what-are-tokens-vectors-and-embeddings-how-do-you-create-them" rel="external" target="_blank">https://saschametzger.com/blog/what-are-tokens-vectors-and-embeddings-how-do-you-create-them</a> .</p>
<p>In the context of an LLM with LangChain, embeddings are used to capture the &ldquo;meaning&rdquo; of text. The closeness of two vectors indicates the degree of correlation between them, where shorter distances imply a stronger correlation, and longer distances suggest a weaker correlation.</p>
<p>Here is an example of how to create vector embeddings using the <code>sentence_transformers</code> library in Python: In this example, <code>embeddings.embed_query(text)</code>â€¯generates embeddings for the given text.</p>
<div class="highlight wrap-code"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#75715e"># load embedding library</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.embeddings <span style="color:#f92672">import</span> HuggingFaceEmbeddings
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># define embedding with using sentence-transformers model from HuggingFace.co</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>embeddings <span style="color:#f92672">=</span> HuggingFaceEmbeddings(
</span></span><span style="display:flex;"><span>    model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;harry potterâ€™s owl is in the castle.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># embed the given text</span>
</span></span><span style="display:flex;"><span>embed_text <span style="color:#f92672">=</span> embeddings<span style="color:#f92672">.</span>embed_query(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># print the first 3 embedding</span>
</span></span><span style="display:flex;"><span>print(embed_text [:<span style="color:#ae81ff">3</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># print out the type of embeddings</span>
</span></span><span style="display:flex;"><span>print(type(embed_text))</span></span></code></pre></div>
<p>The model utilized in this instance is the <code>paraphrase-multilingual-MiniLM</code> from sentence-transformers, known for its resilience, efficiency, and compact size of <code>477MB</code> for local storage. Despite various alternatives, this model is favored for its simplicity and effectiveness. Following the embedding procedure, the embedded data is going to be inserted into VectorStore, ensuring long-term persistence and readiness for subsequent <code>similarity-search</code> operations.</p>
<h4 id="understanding-vectorstore">Understanding VectorStore</h4>
<p>Understanding a VectorStore involves grasping its role in efficiently searching and comparing extensive sets of vectors, which are essential for AI applications by translating words into numerical representations to simplify sentence comparisons based on their semantic meanings.</p>
<ul>
<li>
<p>Functionality of VectorStore: In LangChain, the VectorStore serves as a repository for embeddings, enabling streamlined searches based on semantic similarity. Text undergoes embedding and is then stored in the VectorStore for long-term retention, preparing it for subsequent similarity inquiries.</p>
</li>
<li>
<p>Variety of VectorStore options: LangChain offers support for vector databases as its primary index type, encompassing features like document loaders, text splitters, VectorStores , and retrievers. These databases contain individual nodes alongside their respective embeddings within a VectorStore.</p>
</li>
</ul>
<p>Benefits of utilizing VectorStore: Integrating VectorStore in LangChain provides advantages such as efficient storage and retrieval of embeddings, facilitating quick and accurate similarity searches rooted in semantic relationships. By storing embeddings close to domain-specific datasets, seamless integration with additional metadata is enabled without external queries.</p>
<p>I will be presenting a variety of open-source VectorStores. Among the most popular in the LLM domain are FAISS, Qdrant, Pinecone, and Chroma. Each of these open-source vectorstore databases will be explored through sample code within this book.</p>
<h4 id="utilizing-embedding-and-vectorstore-in-langchain">Utilizing Embedding and VectorStore in LangChain</h4>
<p>In LangChain, embedding and VectorStore collaboratively foster the creation of intelligent agents capable of interpreting and implementing human language commands. Initially, textual data is subjected to processing and transformation into embeddings via appropriate models. Subsequently, these embeddings are deposited in a VectorStore for expeditious retrieval.</p>
<p>Upon receipt of novel instructions or queries, the system may rapidly extract pertinent embeddings from the VectorStore, contrast them against the embeddings derived from the incoming command, and subsequently formulate a reply.</p>
<p>Below is an example of how this might manifest in code, employing the Sentence-Transformers library for embeddings and inserting the embeddings into FAISS open-source VectorStore, which is running in memory.</p>
<div class="highlight wrap-code"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#75715e"># load embedding model</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.embeddings <span style="color:#f92672">import</span> HuggingFaceEmbeddings
</span></span><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> HuggingFaceEmbeddings(
</span></span><span style="display:flex;"><span>    model_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># load vectorstore library</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> langchain_community.vectorstores <span style="color:#f92672">import</span> FAISS
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># insert the embedded data into vectorstore in memory</span>
</span></span><span style="display:flex;"><span>vectorstore <span style="color:#f92672">=</span> FAISS<span style="color:#f92672">.</span>from_texts(
</span></span><span style="display:flex;"><span>    [<span style="color:#e6db74">&#34;harry potter&#39;s owl is in the castle&#34;</span>],
</span></span><span style="display:flex;"><span>    embedding <span style="color:#f92672">=</span> embedding,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(vectorstore)</span></span></code></pre></div>
<p>Once the embedded data is stored in VectorStore, we will explore the process of orchestrating retrieval and chaining to obtain responses from the LLM.</p>

  <footer class="footline">
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/langchain_project_book/index.html">
LangChain AI
          </a>
        </div>
        <script>
          window.index_js_url="/langchain_project_book/searchindex.js?1730158732";
        </script>
        <search><form action="/langchain_project_book/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
        <script>
          var contentLangs=['en'];
        </script>
        <script src="/langchain_project_book/js/auto-complete.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.min.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.stemmer.support.min.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.multi.min.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/lunr/lunr.en.min.js?1730158732" defer></script>
        <script src="/langchain_project_book/js/search.js?1730158732" defer></script>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <ul>
          <li><a class="padding" href="/langchain_project_book/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
        </ul>
        <hr class="padding">
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div id="R-topics">
          <ul class="enlarge morespace collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/preface/index.html"><a class="padding" href="/langchain_project_book/preface/index.html">Preface</a></li>
            <li class="parent " data-nav-id="/langchain_project_book/fundamentals/index.html"><a class="padding" href="/langchain_project_book/fundamentals/index.html">LangChain Fundamentals</a><ul id="R-subsections-c6757c34957c6808b13ecd5148aeca96" class="collapsible-menu">
            <li class="" data-nav-id="/langchain_project_book/fundamentals/architecture/index.html"><a class="padding" href="/langchain_project_book/fundamentals/architecture/index.html">LangChain Architecture</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/select_a_right_lm/index.html"><a class="padding" href="/langchain_project_book/fundamentals/select_a_right_lm/index.html">Select a Right Language Model</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/llm_settings_n_limits/index.html"><a class="padding" href="/langchain_project_book/fundamentals/llm_settings_n_limits/index.html">LLM Settings and Limits</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/thoughts_on_prompt/index.html"><a class="padding" href="/langchain_project_book/fundamentals/thoughts_on_prompt/index.html">Thoughts on Prompt Engineering</a></li>
            <li class="active " data-nav-id="/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html"><a class="padding" href="/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html">Embeddings and VectorStore</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/chains_n_retriever/index.html"><a class="padding" href="/langchain_project_book/fundamentals/chains_n_retriever/index.html">Chains and Retriever</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/document_n_debugging/index.html"><a class="padding" href="/langchain_project_book/fundamentals/document_n_debugging/index.html">Document and Debugging</a></li>
            <li class="" data-nav-id="/langchain_project_book/fundamentals/summary/index.html"><a class="padding" href="/langchain_project_book/fundamentals/summary/index.html">Summary</a></li></ul></li>
            <li class="" data-nav-id="/langchain_project_book/tools_n_lib/index.html"><a class="padding" href="/langchain_project_book/tools_n_lib/index.html">Tools and Libraries</a><ul id="R-subsections-cc34bf23dab60f9112ee939495610dcf" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/doc_sum/index.html"><a class="padding" href="/langchain_project_book/doc_sum/index.html">Document Summarization</a><ul id="R-subsections-76bbd5376befb633d2052d0ea4508ef3" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/ticketing_sys/index.html"><a class="padding" href="/langchain_project_book/ticketing_sys/index.html">Ticketing System</a><ul id="R-subsections-eaa6b154ff31d8e1af72e9555a67f96a" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/langchain_project_book/knowledgebase_semantic_analysis/index.html"><a class="padding" href="/langchain_project_book/knowledgebase_semantic_analysis/index.html">KnowledgeBase Semantic Analysis</a><ul id="R-subsections-c718aa372d1e4f26c29659df75d5d07f" class="collapsible-menu"></ul></li>
          </ul>
        </div>
        <div class="padding footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div>
        <div id="R-menu-footer">
          <hr class="padding default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter">
          <div id="R-prefooter" class="footerLangSwitch footerVariantSwitch footerVisitedLinks">
            <ul>
              <li id="R-select-language-container" class="footerLangSwitch">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-language"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <label class="a11y-only" for="R-select-language">Language</label>
                    <select id="R-select-language" onchange="location = this.querySelector( this.value ).dataset.url;">
                      <option id="R-select-language-en" value="#R-select-language-en" data-url="/langchain_project_book/fundamentals/embedding_n_vectorstore/index.html" lang="en-us" selected></option>
                    </select>
                  </div>
                  <div class="clear"></div>
                </div>
              </li>
              <li id="R-select-variant-container" class="footerVariantSwitch">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-paint-brush"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <label class="a11y-only" for="R-select-variant">Theme</label>
                    <select id="R-select-variant" onchange="window.variants && variants.changeVariant( this.value );">
                      <option id="R-select-variant-auto" value="auto" selected>Auto</option>
                    </select>
                  </div>
                  <div class="clear"></div>
                </div>
                <script>window.variants && variants.markSelectedVariant();</script>
              </li>
              <li class="footerVisitedLinks">
                <div class="padding menu-control">
                  <i class="fa-fw fas fa-history"></i>
                  <span>&nbsp;</span>
                  <div class="control-style">
                    <button onclick="clearHistory();">Clear History</button>
                  </div>
                  <div class="clear"></div>
                </div>
              </li>
            </ul>
          </div>
          <div id="R-footer" class="footerFooter showFooter">
        <p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p>
          </div>
        </div>
      </div>
    </aside>
    <script src="/langchain_project_book/js/clipboard.min.js?1730158732" defer></script>
    <script src="/langchain_project_book/js/perfect-scrollbar.min.js?1730158732" defer></script>
    <script src="/langchain_project_book/js/theme.js?1730158732" defer></script>
  </body>
</html>
